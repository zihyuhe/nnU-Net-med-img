{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tN-RevPM5uaO"
   },
   "source": [
    "## 環境設置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25605,
     "status": "ok",
     "timestamp": 1742456166481,
     "user": {
      "displayName": "Group D SC201 OCT24",
      "userId": "05617796782478803590"
     },
     "user_tz": -480
    },
    "id": "PEA_vjQb6erF",
    "outputId": "d0d9eb95-fc14-4de6-9c13-8e546fb148e2"
   },
   "outputs": [],
   "source": [
    "# Mount to Google Drive\n",
    "# from google.colab import drive\n",
    "# # drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 98779,
     "status": "ok",
     "timestamp": 1742456265258,
     "user": {
      "displayName": "Group D SC201 OCT24",
      "userId": "05617796782478803590"
     },
     "user_tz": -480
    },
    "id": "0qq1xPCW6ALm",
    "outputId": "b4f07b9d-417e-4564-c79d-6c4617ea325a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install nnunetv2 -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "HJAqL1VwWT6U"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['nnUNet_raw'] = './nnU_Base/nnUNet_raw_data'\n",
    "os.environ['nnUNet_preprocessed'] = './nnU_Base/nnUNet_preprocessed'\n",
    "os.environ['nnUNet_results'] = './nnU_Base/nnUNet_trained_models'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yi_2R1YkeVRw"
   },
   "source": [
    "## 用程式碼上傳raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "uM4_KGWCefR8"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "\n",
    "def copy_single_file(src_file, dest_file):\n",
    "    \"\"\"Copy a single file with error handling\"\"\"\n",
    "    try:\n",
    "        # Create parent directories if they don't exist\n",
    "        os.makedirs(os.path.dirname(dest_file), exist_ok=True)\n",
    "\n",
    "        # Copy the file\n",
    "        shutil.copy2(src_file, dest_file)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error copying {src_file} to {dest_file}: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "def get_all_files(source_dir):\n",
    "    \"\"\"Get a list of all files in the directory and its subdirectories\"\"\"\n",
    "    all_files = []\n",
    "    for root, _, files in os.walk(source_dir):\n",
    "        for file in files:\n",
    "            src_file = os.path.join(root, file)\n",
    "            all_files.append(src_file)\n",
    "    return all_files\n",
    "\n",
    "def robust_copy_directory(source_dir, dest_dir, start_idx=0, batch_size=5, sleep_time=2):\n",
    "    \"\"\"\n",
    "    Copy files from source_dir to dest_dir with memory management\n",
    "\n",
    "    Args:\n",
    "        source_dir: Source directory\n",
    "        dest_dir: Destination directory\n",
    "        start_idx: Index to start copying from (useful for resuming)\n",
    "        batch_size: Number of files to copy before pausing\n",
    "        sleep_time: Time to sleep between batches in seconds\n",
    "    \"\"\"\n",
    "    # Create destination directory if it doesn't exist\n",
    "    if not os.path.exists(dest_dir):\n",
    "        os.makedirs(dest_dir)\n",
    "\n",
    "    # Get list of all files\n",
    "    all_files = get_all_files(source_dir)\n",
    "    total_files = len(all_files)\n",
    "\n",
    "    if start_idx >= total_files:\n",
    "        print(f\"Start index {start_idx} is greater than total files {total_files}\")\n",
    "        return\n",
    "\n",
    "    print(f\"Found {total_files} files to copy, starting from index {start_idx}\")\n",
    "\n",
    "    # Process files in small batches\n",
    "    for i in range(start_idx, total_files, batch_size):\n",
    "        batch_end = min(i + batch_size, total_files)\n",
    "        print(f\"\\nProcessing batch {i//batch_size + 1}: files {i+1}-{batch_end} of {total_files}\")\n",
    "\n",
    "        # Process each file in the current batch\n",
    "        for j in range(i, batch_end):\n",
    "            src_file = all_files[j]\n",
    "            # Calculate relative path to maintain directory structure\n",
    "            rel_path = os.path.relpath(src_file, source_dir)\n",
    "            dest_file = os.path.join(dest_dir, rel_path)\n",
    "\n",
    "            print(f\"Copying file {j+1}/{total_files}: {rel_path}\")\n",
    "            success = copy_single_file(src_file, dest_file)\n",
    "\n",
    "            # Force garbage collection after each file\n",
    "            gc.collect()\n",
    "\n",
    "        # After each batch, print progress and pause\n",
    "        print(f\"Completed {batch_end}/{total_files} files ({(batch_end/total_files)*100:.1f}%)\")\n",
    "\n",
    "        if batch_end < total_files:\n",
    "            print(f\"Pausing for {sleep_time} seconds before next batch...\")\n",
    "            time.sleep(sleep_time)\n",
    "\n",
    "            # More aggressive garbage collection every 50 files\n",
    "            if (batch_end % 50) < batch_size:\n",
    "                print(\"Performing extensive garbage collection...\")\n",
    "                for _ in range(3):\n",
    "                    gc.collect()\n",
    "                time.sleep(5)\n",
    "\n",
    "            # Print resume information\n",
    "            print(f\"\"\"\n",
    "If this process freezes, you can resume by running:\n",
    "robust_copy_directory(\"{source_dir}\", \"{dest_dir}\", start_idx={batch_end}, batch_size={batch_size})\n",
    "\"\"\")\n",
    "\n",
    "    print(f\"\\nCopy complete! Copied {total_files} files from {source_dir} to {dest_dir}\")\n",
    "\n",
    "def verify_copy(source_dir, dest_dir):\n",
    "    \"\"\"Verify that all files were copied correctly\"\"\"\n",
    "    source_files = get_all_files(source_dir)\n",
    "    dest_files = get_all_files(dest_dir)\n",
    "\n",
    "    # Convert to relative paths for comparison\n",
    "    source_rel_paths = set(os.path.relpath(f, source_dir) for f in source_files)\n",
    "    dest_rel_paths = set(os.path.relpath(f, dest_dir) for f in dest_files)\n",
    "\n",
    "    missing_files = source_rel_paths - dest_rel_paths\n",
    "\n",
    "    print(f\"Source files: {len(source_rel_paths)}\")\n",
    "    print(f\"Destination files: {len(dest_rel_paths)}\")\n",
    "\n",
    "    if missing_files:\n",
    "        print(f\"WARNING: {len(missing_files)} files were not copied!\")\n",
    "        if len(missing_files) < 10:\n",
    "            print(\"Missing files:\")\n",
    "            for f in missing_files:\n",
    "                print(f\"  - {f}\")\n",
    "        else:\n",
    "            print(\"First 10 missing files:\")\n",
    "            for f in list(missing_files)[:10]:\n",
    "                print(f\"  - {f}\")\n",
    "    else:\n",
    "        print(\"All files were copied successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 5021308,
     "status": "ok",
     "timestamp": 1742263659110,
     "user": {
      "displayName": "LAB AI",
      "userId": "05090763676444143877"
     },
     "user_tz": -480
    },
    "id": "nNRwZPDqeatH",
    "outputId": "d5d29b34-39ad-44b2-92f7-7d2429ba25e6"
   },
   "outputs": [],
   "source": [
    "source_directory = './nnU_Base/nnUNet_raw_data/Dataset001_MYTASK'\n",
    "destination_directory = './nnU_Base/nnUNet_raw_data/Dataset001_MYTASK'\n",
    "\n",
    "# robust_copy_directory(source_directory, destination_directory)\n",
    "\n",
    "# # After copying completes, verify that everything was copied correctly\n",
    "# verify_copy(source_directory, destination_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "lc7_R4EBWjL1"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def generate_dataset_json(output_folder: str,\n",
    "                          channel_names: dict,\n",
    "                          labels: dict,\n",
    "                          num_training_cases: int,\n",
    "                          file_ending: str,\n",
    "                          dataset_name: str = None,\n",
    "                          overwrite_image_reader_writer: str = None,\n",
    "                          ):\n",
    "  \"\"\"\n",
    "  製作如下的json檔\n",
    "  {\n",
    "      \"name\": \"nnunet-how-to\",\n",
    "      \"channel_names\": {\n",
    "          \"0\": \"CT\"\n",
    "      },\n",
    "      \"labels\": {\n",
    "          \"background\": 0,\n",
    "          \"AA\": 1\n",
    "      },\n",
    "      \"numTraining\": 10,\n",
    "      \"file_ending\": \"nii.gz\",\n",
    "      \"overwrite_image_reader_writer\": \"SimpleITKIO\"\n",
    "  }\n",
    "  \"\"\"\n",
    "  # channel names need strings as keys\n",
    "  keys = list(channel_names.keys())\n",
    "  for k in keys:\n",
    "      if not isinstance(k, str):\n",
    "          channel_names[str(k)] = channel_names[k]\n",
    "          del channel_names[k]\n",
    "\n",
    "  # labels need ints as values\n",
    "  for l in labels.keys():\n",
    "      value = labels[l]\n",
    "      if isinstance(value, (tuple, list)):\n",
    "          value = tuple([int(i) for i in value])\n",
    "          labels[l] = value\n",
    "      else:\n",
    "          labels[l] = int(labels[l])\n",
    "\n",
    "  dataset_json = {\n",
    "      'name': '',\n",
    "      'channel_names': channel_names,\n",
    "      'labels': labels,\n",
    "      'numTraining': num_training_cases,\n",
    "      'file_ending': file_ending,\n",
    "      'overwrite_image_reader_writer': ''\n",
    "  }\n",
    "\n",
    "  if dataset_name is not None:\n",
    "      dataset_json['name'] = dataset_name\n",
    "  if overwrite_image_reader_writer is not None:\n",
    "      dataset_json['overwrite_image_reader_writer'] = overwrite_image_reader_writer\n",
    "\n",
    "  save_path = os.path.join(output_folder, 'dataset.json')\n",
    "  with open(save_path, 'w') as f:\n",
    "      json.dump(dataset_json, f, indent=4)\n",
    "\n",
    "  print(f'dataset.json saved to {save_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1741931309010,
     "user": {
      "displayName": "LAB AI",
      "userId": "05090763676444143877"
     },
     "user_tz": -480
    },
    "id": "SFJdpd_tWr7s",
    "outputId": "9f526648-1c9f-484b-8cc1-400b82154380"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset.json saved to ./nnU_Base/nnUNet_raw_data/Dataset001_MYTASK\\dataset.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "json_dir_path = './nnU_Base/nnUNet_raw_data/Dataset001_MYTASK'\n",
    "generate_dataset_json(json_dir_path,\n",
    "                      {0: 'CT'},                              # channel_names\n",
    "                      {\"background\": 0, \"AA\": 1},    # labels\n",
    "                      300,                                    # num_training_cases\n",
    "                      '.nii.gz',                              # file_ending\n",
    "                      overwrite_image_reader_writer='SimpleITKIO'\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mWJypjO4WhdQ"
   },
   "source": [
    "## plan and preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aDydL2H0951P"
   },
   "source": [
    "nnUNetv2_plan_and_preprocess = nnUNetv2_extract_fingerprint + nnUNetv2_plan_experiment + nnUNetv2_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "id": "74I_7uTf8ByW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: nnUNetv2_plan_and_preprocess [-h] [-d D [D ...]] [-fpe FPE]\n",
      "                                    [-npfp NPFP] [--verify_dataset_integrity]\n",
      "                                    [--no_pp] [--clean] [-pl PL]\n",
      "                                    [-gpu_memory_target GPU_MEMORY_TARGET]\n",
      "                                    [-preprocessor_name PREPROCESSOR_NAME]\n",
      "                                    [-overwrite_target_spacing OVERWRITE_TARGET_SPACING [OVERWRITE_TARGET_SPACING ...]]\n",
      "                                    [-overwrite_plans_name OVERWRITE_PLANS_NAME]\n",
      "                                    [-c C [C ...]] [-np NP [NP ...]]\n",
      "                                    [--verbose]\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  -d D [D ...]          [REQUIRED] List of dataset IDs. Example: 2 4 5. This\n",
      "                        will run fingerprint extraction, experiment planning\n",
      "                        and preprocessing for these datasets. Can of course\n",
      "                        also be just one dataset\n",
      "  -fpe FPE              [OPTIONAL] Name of the Dataset Fingerprint Extractor\n",
      "                        class that should be used. Default is\n",
      "                        'DatasetFingerprintExtractor'.\n",
      "  -npfp NPFP            [OPTIONAL] Number of processes used for fingerprint\n",
      "                        extraction. Default: 8\n",
      "  --verify_dataset_integrity\n",
      "                        [RECOMMENDED] set this flag to check the dataset\n",
      "                        integrity. This is useful and should be done once for\n",
      "                        each dataset!\n",
      "  --no_pp               [OPTIONAL] Set this to only run fingerprint extraction\n",
      "                        and experiment planning (no preprocesing). Useful for\n",
      "                        debugging.\n",
      "  --clean               [OPTIONAL] Set this flag to overwrite existing\n",
      "                        fingerprints. If this flag is not set and a\n",
      "                        fingerprint already exists, the fingerprint extractor\n",
      "                        will not run. REQUIRED IF YOU CHANGE THE DATASET\n",
      "                        FINGERPRINT EXTRACTOR OR MAKE CHANGES TO THE DATASET!\n",
      "  -pl PL                [OPTIONAL] Name of the Experiment Planner class that\n",
      "                        should be used. Default is 'ExperimentPlanner'. Note:\n",
      "                        There is no longer a distinction between 2d and 3d\n",
      "                        planner. It's an all in one solution now. Wuch. Such\n",
      "                        amazing.\n",
      "  -gpu_memory_target GPU_MEMORY_TARGET\n",
      "                        [OPTIONAL] DANGER ZONE! Sets a custom GPU memory\n",
      "                        target (in GB). Default: None (=Planner class default\n",
      "                        is used). Changing this will affect patch and batch\n",
      "                        size and will definitely affect your models\n",
      "                        performance! Only use this if you really know what you\n",
      "                        are doing and NEVER use this without running the\n",
      "                        default nnU-Net first as a baseline.\n",
      "  -preprocessor_name PREPROCESSOR_NAME\n",
      "                        [OPTIONAL] DANGER ZONE! Sets a custom preprocessor\n",
      "                        class. This class must be located in\n",
      "                        nnunetv2.preprocessing. Default:\n",
      "                        'DefaultPreprocessor'. Changing this may affect your\n",
      "                        models performance! Only use this if you really know\n",
      "                        what you are doing and NEVER use this without running\n",
      "                        the default nnU-Net first (as a baseline).\n",
      "  -overwrite_target_spacing OVERWRITE_TARGET_SPACING [OVERWRITE_TARGET_SPACING ...]\n",
      "                        [OPTIONAL] DANGER ZONE! Sets a custom target spacing\n",
      "                        for the 3d_fullres and 3d_cascade_fullres\n",
      "                        configurations. Default: None [no changes]. Changing\n",
      "                        this will affect image size and potentially patch and\n",
      "                        batch size. This will definitely affect your models\n",
      "                        performance! Only use this if you really know what you\n",
      "                        are doing and NEVER use this without running the\n",
      "                        default nnU-Net first (as a baseline). Changing the\n",
      "                        target spacing for the other configurations is\n",
      "                        currently not implemented. New target spacing must be\n",
      "                        a list of three numbers!\n",
      "  -overwrite_plans_name OVERWRITE_PLANS_NAME\n",
      "                        [OPTIONAL] uSE A CUSTOM PLANS IDENTIFIER. If you used\n",
      "                        -gpu_memory_target, -preprocessor_name or\n",
      "                        -overwrite_target_spacing it is best practice to use\n",
      "                        -overwrite_plans_name to generate a differently named\n",
      "                        plans file such that the nnunet default plans are not\n",
      "                        overwritten. You will then need to specify your custom\n",
      "                        plans file with -p whenever running other nnunet\n",
      "                        commands (training, inference etc)\n",
      "  -c C [C ...]          [OPTIONAL] Configurations for which the preprocessing\n",
      "                        should be run. Default: 2d 3d_fullres 3d_lowres.\n",
      "                        3d_cascade_fullres does not need to be specified\n",
      "                        because it uses the data from 3d_fullres.\n",
      "                        Configurations that do not exist for some dataset will\n",
      "                        be skipped.\n",
      "  -np NP [NP ...]       [OPTIONAL] Use this to define how many processes are\n",
      "                        to be used. If this is just one number then this\n",
      "                        number of processes is used for all configurations\n",
      "                        specified with -c. If it's a list of numbers this list\n",
      "                        must have as many elements as there are\n",
      "                        configurations. We then iterate over zip(configs,\n",
      "                        num_processes) to determine then umber of processes\n",
      "                        used for each configuration. More processes is always\n",
      "                        faster (up to the number of threads your PC can\n",
      "                        support, so 8 for a 4 core CPU with hyperthreading. If\n",
      "                        you don't know what that is then dont touch it, or at\n",
      "                        least don't increase it!). DANGER: More often than not\n",
      "                        the number of processes that can be used is limited by\n",
      "                        the amount of RAM available. Image resampling takes up\n",
      "                        a lot of RAM. MONITOR RAM USAGE AND DECREASE -np IF\n",
      "                        YOUR RAM FILLS UP TOO MUCH!. Default: 8 processes for\n",
      "                        2d, 4 for 3d_fullres, 8 for 3d_lowres and 4 for\n",
      "                        everything else\n",
      "  --verbose             Set this to print a lot of stuff. Useful for\n",
      "                        debugging. Will disable progress bar! Recommended for\n",
      "                        cluster environments\n"
     ]
    }
   ],
   "source": [
    "!nnUNetv2_plan_and_preprocess -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# os.environ['nnUNet_raw'] = 'C:/Users/CUTY/Desktop/TO DELETE/AOCR2024/nnU_Base/nnUNet_raw_data'\n",
    "# os.environ['nnUNet_preprocessed'] = 'C:/Users/CUTY/Desktop/TO DELETE/AOCR2024/nnU_Base/nnUNet_preprocessed'\n",
    "# os.environ['nnUNet_results'] = 'C:/Users/CUTY/Desktop/TO DELETE/AOCR2024/nnU_Base/nnUNet_trained_models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# print(os.path.abspath(\"./nnU_Base/nnUNet_raw_data/Task001_MYTASK\"))\n",
    "# print(os.listdir(\"./nnU_Base/nnUNet_raw_data\"))\n",
    "# print(os.listdir(\"./nnU_Base/nnUNet_raw_data/Task001_MYTASK\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 245189,
     "status": "ok",
     "timestamp": 1742263904304,
     "user": {
      "displayName": "LAB AI",
      "userId": "05090763676444143877"
     },
     "user_tz": -480
    },
    "id": "GKUGihBW9x0r",
    "outputId": "5f410508-ea23-46d8-d35d-3327769812ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset001_MYTASK\n",
      "Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> reader/writer\n",
      "\n",
      "####################\n",
      "verify_dataset_integrity Done. \n",
      "If you didn't see any error messages then your dataset is most likely OK!\n",
      "####################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['nnUNet_raw'] = r'C:\\Users\\CUTY\\Desktop\\AOR\\nnU_Base\\nnUNet_raw_data'\n",
    "os.environ['nnUNet_preprocessed'] = r'C:\\Users\\CUTY\\Desktop\\AOR\\nnU_Base\\nnUNet_preprocessed'\n",
    "os.environ['nnUNet_results'] = r'C:\\Users\\CUTY\\Desktop\\AOR\\nnU_Base\\nnUNet_trained_models'\n",
    "\n",
    "# import sys\n",
    "# print(sys.executable)\n",
    "\n",
    "!nnUNetv2_extract_fingerprint -d 1 --verify_dataset_integrity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 15745,
     "status": "ok",
     "timestamp": 1742263920052,
     "user": {
      "displayName": "LAB AI",
      "userId": "05090763676444143877"
     },
     "user_tz": -480
    },
    "id": "Ibk9zuTeoAH5",
    "outputId": "d3999188-9b56-4155-de0b-79232f8e46ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\CUTY\\Desktop\\AOR\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [5.         0.70410156 0.70410156]. \n",
      "Current patch size: (np.int64(56), np.int64(320), np.int64(256)). \n",
      "Current median shape: [ 94.         497.08737864 497.08737864]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [5.         0.72522461 0.72522461]. \n",
      "Current patch size: (np.int64(56), np.int64(320), np.int64(256)). \n",
      "Current median shape: [ 94.         482.60910548 482.60910548]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [5.         0.74698135 0.74698135]. \n",
      "Current patch size: (np.int64(64), np.int64(256), np.int64(256)). \n",
      "Current median shape: [ 94.         468.55252959 468.55252959]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [5.         0.76939079 0.76939079]. \n",
      "Current patch size: (np.int64(64), np.int64(256), np.int64(256)). \n",
      "Current median shape: [ 94.         454.90536853 454.90536853]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [5.         0.79247251 0.79247251]. \n",
      "Current patch size: (np.int64(64), np.int64(256), np.int64(256)). \n",
      "Current median shape: [ 94.        441.6556976 441.6556976]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [5.         0.81624669 0.81624669]. \n",
      "Current patch size: (np.int64(64), np.int64(256), np.int64(256)). \n",
      "Current median shape: [ 94.         428.79193942 428.79193942]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [5.         0.84073409 0.84073409]. \n",
      "Current patch size: (np.int64(64), np.int64(256), np.int64(256)). \n",
      "Current median shape: [ 94.         416.30285381 416.30285381]\n",
      "Dropping 3d_lowres config because the image size difference to 3d_fullres is too small. 3d_fullres: [ 94. 512. 512.], 3d_lowres: [94, 416, 416]\n",
      "2D U-Net configuration:\n",
      "{'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 35, 'patch_size': (np.int64(512), np.int64(512)), 'median_image_size_in_voxels': array([512., 512.]), 'spacing': array([0.68359375, 0.68359375]), 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.ResidualEncoderUNet', 'arch_kwargs': {'n_stages': 8, 'features_per_stage': (32, 64, 128, 256, 512, 512, 512, 512), 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': ((3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3)), 'strides': ((1, 1), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2)), 'n_blocks_per_stage': (1, 3, 4, 6, 6, 6, 6, 6), 'n_conv_per_stage_decoder': (1, 1, 1, 1, 1, 1, 1), 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ('conv_op', 'norm_op', 'dropout_op', 'nonlin')}, 'batch_dice': True}\n",
      "\n",
      "Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> reader/writer\n",
      "3D fullres U-Net configuration:\n",
      "{'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': (np.int64(56), np.int64(320), np.int64(256)), 'median_image_size_in_voxels': array([ 94., 512., 512.]), 'spacing': array([5.        , 0.68359375, 0.68359375]), 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.ResidualEncoderUNet', 'arch_kwargs': {'n_stages': 7, 'features_per_stage': (32, 64, 128, 256, 320, 320, 320), 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': ((1, 3, 3), (1, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3)), 'strides': ((1, 1, 1), (1, 2, 2), (1, 2, 2), (2, 2, 2), (2, 2, 2), (2, 2, 2), (1, 2, 2)), 'n_blocks_per_stage': (1, 3, 4, 6, 6, 6, 6), 'n_conv_per_stage_decoder': (1, 1, 1, 1, 1, 1), 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ('conv_op', 'norm_op', 'dropout_op', 'nonlin')}, 'batch_dice': False}\n",
      "\n",
      "Plans were saved to C:\\Users\\CUTY\\Desktop\\AOR\\nnU_Base\\nnUNet_preprocessed\\Dataset001_MYTASK\\nnUNetResEncUNetLPlans.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "!nnUNetv2_plan_experiment -d 1 -pl nnUNetPlannerResEncL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 4215,
     "status": "ok",
     "timestamp": 1741651742654,
     "user": {
      "displayName": "LAB AI",
      "userId": "05090763676444143877"
     },
     "user_tz": -480
    },
    "id": "ZwhdxMGNpp62",
    "outputId": "4d517df9-253c-4bce-9c90-3dac8d5b7882"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: nnUNetv2_preprocess [-h] [-d D [D ...]] [-plans_name PLANS_NAME]\n",
      "                           [-c C [C ...]] [-np NP [NP ...]] [--verbose]\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  -d D [D ...]          [REQUIRED] List of dataset IDs. Example: 2 4 5. This\n",
      "                        will run fingerprint extraction, experiment planning\n",
      "                        and preprocessing for these datasets. Can of course\n",
      "                        also be just one dataset\n",
      "  -plans_name PLANS_NAME\n",
      "                        [OPTIONAL] You can use this to specify a custom plans\n",
      "                        file that you may have generated\n",
      "  -c C [C ...]          [OPTIONAL] Configurations for which the preprocessing\n",
      "                        should be run. Default: 2d 3d_fullres 3d_lowres.\n",
      "                        3d_cascade_fullres does not need to be specified\n",
      "                        because it uses the data from 3d_fullres.\n",
      "                        Configurations that do not exist for some dataset will\n",
      "                        be skipped.\n",
      "  -np NP [NP ...]       [OPTIONAL] Use this to define how many processes are\n",
      "                        to be used. If this is just one number then this\n",
      "                        number of processes is used for all configurations\n",
      "                        specified with -c. If it's a list of numbers this list\n",
      "                        must have as many elements as there are\n",
      "                        configurations. We then iterate over zip(configs,\n",
      "                        num_processes) to determine then umber of processes\n",
      "                        used for each configuration. More processes is always\n",
      "                        faster (up to the number of threads your PC can\n",
      "                        support, so 8 for a 4 core CPU with hyperthreading. If\n",
      "                        you don't know what that is then dont touch it, or at\n",
      "                        least don't increase it!). DANGER: More often than not\n",
      "                        the number of processes that can be used is limited by\n",
      "                        the amount of RAM available. Image resampling takes up\n",
      "                        a lot of RAM. MONITOR RAM USAGE AND DECREASE -np IF\n",
      "                        YOUR RAM FILLS UP TOO MUCH!. Default: 8 processes for\n",
      "                        2d, 4 for 3d_fullres, 8 for 3d_lowres and 4 for\n",
      "                        everything else\n",
      "  --verbose             Set this to print a lot of stuff. Useful for\n",
      "                        debugging. Will disable progress bar! Recommended for\n",
      "                        cluster environments\n"
     ]
    }
   ],
   "source": [
    "!nnUNetv2_preprocess -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 1890650,
     "status": "ok",
     "timestamp": 1742265810704,
     "user": {
      "displayName": "LAB AI",
      "userId": "05090763676444143877"
     },
     "user_tz": -480
    },
    "id": "nYxtjv4dqEVO",
    "outputId": "1bddb41d-de54-4e70-f8fb-4981f6f928c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing dataset Dataset001_MYTASK\n",
      "Configuration: 3d_fullres...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/300 [00:00<?, ?it/s]\n",
      "  0%|          | 1/300 [00:12<1:03:22, 12.72s/it]\n",
      "  1%|          | 2/300 [00:13<28:04,  5.65s/it]  \n",
      "  1%|          | 3/300 [00:14<17:01,  3.44s/it]\n",
      "  1%|▏         | 4/300 [00:15<12:14,  2.48s/it]\n",
      "  2%|▏         | 5/300 [00:20<16:33,  3.37s/it]\n",
      "  2%|▏         | 6/300 [00:20<11:34,  2.36s/it]\n",
      "  2%|▏         | 7/300 [00:26<16:27,  3.37s/it]\n",
      "  3%|▎         | 8/300 [00:27<13:41,  2.81s/it]\n",
      "  3%|▎         | 9/300 [00:29<12:53,  2.66s/it]\n",
      "  3%|▎         | 10/300 [00:32<12:56,  2.68s/it]\n",
      "  4%|▎         | 11/300 [00:35<12:40,  2.63s/it]\n",
      "  4%|▍         | 12/300 [00:38<13:30,  2.81s/it]\n",
      "  4%|▍         | 13/300 [00:38<09:57,  2.08s/it]\n",
      "  5%|▍         | 14/300 [00:41<10:16,  2.16s/it]\n",
      "  5%|▌         | 15/300 [00:44<11:55,  2.51s/it]\n",
      "  5%|▌         | 16/300 [00:48<14:03,  2.97s/it]\n",
      "  6%|▌         | 17/300 [00:49<10:56,  2.32s/it]\n",
      "  6%|▌         | 18/300 [00:53<14:02,  2.99s/it]\n",
      "  6%|▋         | 19/300 [00:57<14:11,  3.03s/it]\n",
      "  7%|▋         | 20/300 [01:02<17:57,  3.85s/it]\n",
      "  7%|▋         | 21/300 [01:07<18:43,  4.03s/it]\n",
      "  7%|▋         | 22/300 [01:07<14:02,  3.03s/it]\n",
      "  8%|▊         | 23/300 [01:08<11:11,  2.42s/it]\n",
      "  8%|▊         | 24/300 [01:11<11:33,  2.51s/it]\n",
      "  8%|▊         | 25/300 [01:17<16:23,  3.58s/it]\n",
      "  9%|▊         | 26/300 [01:17<11:34,  2.53s/it]\n",
      "  9%|▉         | 27/300 [01:19<10:24,  2.29s/it]\n",
      "  9%|▉         | 28/300 [01:22<11:22,  2.51s/it]\n",
      " 10%|▉         | 29/300 [01:30<18:11,  4.03s/it]\n",
      " 10%|█         | 30/300 [01:31<14:11,  3.15s/it]\n",
      " 10%|█         | 31/300 [01:34<14:22,  3.21s/it]\n",
      " 11%|█         | 32/300 [01:34<10:09,  2.27s/it]\n",
      " 11%|█         | 33/300 [01:42<17:59,  4.04s/it]\n",
      " 11%|█▏        | 34/300 [01:45<16:18,  3.68s/it]\n",
      " 12%|█▏        | 35/300 [01:47<13:38,  3.09s/it]\n",
      " 12%|█▏        | 36/300 [01:52<16:10,  3.68s/it]\n",
      " 12%|█▏        | 37/300 [01:52<11:24,  2.60s/it]\n",
      " 13%|█▎        | 38/300 [01:56<13:30,  3.09s/it]\n",
      " 13%|█▎        | 39/300 [01:57<10:52,  2.50s/it]\n",
      " 13%|█▎        | 40/300 [02:02<13:29,  3.11s/it]\n",
      " 14%|█▎        | 41/300 [02:08<17:53,  4.15s/it]\n",
      " 14%|█▍        | 42/300 [02:09<12:44,  2.96s/it]\n",
      " 15%|█▍        | 44/300 [02:17<14:51,  3.48s/it]\n",
      " 15%|█▌        | 45/300 [02:19<13:02,  3.07s/it]\n",
      " 15%|█▌        | 46/300 [02:19<09:49,  2.32s/it]\n",
      " 16%|█▌        | 47/300 [02:20<08:44,  2.07s/it]\n",
      " 16%|█▌        | 48/300 [02:27<13:58,  3.33s/it]\n",
      " 16%|█▋        | 49/300 [02:28<10:54,  2.61s/it]\n",
      " 17%|█▋        | 50/300 [02:30<10:38,  2.55s/it]\n",
      " 17%|█▋        | 51/300 [02:32<09:27,  2.28s/it]\n",
      " 17%|█▋        | 52/300 [02:37<13:32,  3.27s/it]\n",
      " 18%|█▊        | 53/300 [02:39<11:27,  2.78s/it]\n",
      " 18%|█▊        | 54/300 [02:40<09:14,  2.26s/it]\n",
      " 18%|█▊        | 55/300 [02:43<10:31,  2.58s/it]\n",
      " 19%|█▊        | 56/300 [02:44<08:26,  2.08s/it]\n",
      " 19%|█▉        | 57/300 [02:49<12:15,  3.03s/it]\n",
      " 19%|█▉        | 58/300 [02:50<08:40,  2.15s/it]\n",
      " 20%|█▉        | 59/300 [02:51<07:52,  1.96s/it]\n",
      " 20%|██        | 60/300 [02:56<10:56,  2.73s/it]\n",
      " 20%|██        | 61/300 [02:58<10:09,  2.55s/it]\n",
      " 21%|██        | 62/300 [02:58<07:33,  1.91s/it]\n",
      " 21%|██        | 63/300 [02:58<05:37,  1.42s/it]\n",
      " 21%|██▏       | 64/300 [03:09<16:11,  4.11s/it]\n",
      " 22%|██▏       | 65/300 [03:10<12:35,  3.21s/it]\n",
      " 22%|██▏       | 66/300 [03:11<10:18,  2.64s/it]\n",
      " 22%|██▏       | 67/300 [03:13<09:39,  2.49s/it]\n",
      " 23%|██▎       | 68/300 [03:16<09:25,  2.44s/it]\n",
      " 23%|██▎       | 69/300 [03:20<11:41,  3.04s/it]\n",
      " 23%|██▎       | 70/300 [03:21<08:36,  2.25s/it]\n",
      " 24%|██▎       | 71/300 [03:24<09:49,  2.57s/it]\n",
      " 24%|██▍       | 72/300 [03:25<08:06,  2.13s/it]\n",
      " 24%|██▍       | 73/300 [03:32<13:33,  3.58s/it]\n",
      " 25%|██▍       | 74/300 [03:32<09:54,  2.63s/it]\n",
      " 25%|██▌       | 75/300 [03:33<07:34,  2.02s/it]\n",
      " 25%|██▌       | 76/300 [03:33<05:23,  1.45s/it]\n",
      " 26%|██▌       | 77/300 [03:41<12:52,  3.46s/it]\n",
      " 26%|██▌       | 78/300 [03:43<10:25,  2.82s/it]\n",
      " 26%|██▋       | 79/300 [03:43<08:16,  2.25s/it]\n",
      " 27%|██▋       | 80/300 [03:45<07:05,  1.94s/it]\n",
      " 27%|██▋       | 81/300 [03:51<12:00,  3.29s/it]\n",
      " 27%|██▋       | 82/300 [03:51<08:35,  2.37s/it]\n",
      " 28%|██▊       | 83/300 [03:56<10:41,  2.96s/it]\n",
      " 28%|██▊       | 84/300 [04:01<12:47,  3.55s/it]\n",
      " 28%|██▊       | 85/300 [04:03<11:17,  3.15s/it]\n",
      " 29%|██▊       | 86/300 [04:04<09:29,  2.66s/it]\n",
      " 29%|██▉       | 87/300 [04:10<12:37,  3.56s/it]\n",
      " 29%|██▉       | 88/300 [04:14<12:32,  3.55s/it]\n",
      " 30%|███       | 90/300 [04:14<06:46,  1.94s/it]\n",
      " 30%|███       | 91/300 [04:22<12:39,  3.63s/it]\n",
      " 31%|███       | 92/300 [04:23<10:01,  2.89s/it]\n",
      " 31%|███       | 93/300 [04:25<08:30,  2.46s/it]\n",
      " 31%|███▏      | 94/300 [04:28<09:17,  2.71s/it]\n",
      " 32%|███▏      | 95/300 [04:30<08:46,  2.57s/it]\n",
      " 32%|███▏      | 96/300 [04:34<09:46,  2.88s/it]\n",
      " 32%|███▏      | 97/300 [04:36<09:28,  2.80s/it]\n",
      " 33%|███▎      | 98/300 [04:37<07:39,  2.27s/it]\n",
      " 33%|███▎      | 99/300 [04:39<07:03,  2.11s/it]\n",
      " 33%|███▎      | 100/300 [04:46<12:08,  3.64s/it]\n",
      " 34%|███▎      | 101/300 [04:47<08:52,  2.68s/it]\n",
      " 34%|███▍      | 102/300 [04:48<06:59,  2.12s/it]\n",
      " 34%|███▍      | 103/300 [04:49<06:27,  1.97s/it]\n",
      " 35%|███▍      | 104/300 [04:55<09:44,  2.98s/it]\n",
      " 35%|███▌      | 105/300 [04:55<07:16,  2.24s/it]\n",
      " 35%|███▌      | 106/300 [04:58<08:17,  2.57s/it]\n",
      " 36%|███▌      | 107/300 [05:03<10:09,  3.16s/it]\n",
      " 36%|███▌      | 108/300 [05:06<10:16,  3.21s/it]\n",
      " 36%|███▋      | 109/300 [05:09<09:39,  3.03s/it]\n",
      " 37%|███▋      | 110/300 [05:12<09:36,  3.03s/it]\n",
      " 37%|███▋      | 111/300 [05:16<10:18,  3.27s/it]\n",
      " 37%|███▋      | 112/300 [05:16<07:22,  2.35s/it]\n",
      " 38%|███▊      | 113/300 [05:18<06:55,  2.22s/it]\n",
      " 38%|███▊      | 114/300 [05:22<08:56,  2.89s/it]\n",
      " 38%|███▊      | 115/300 [05:23<07:09,  2.32s/it]\n",
      " 39%|███▊      | 116/300 [05:28<09:10,  2.99s/it]\n",
      " 39%|███▉      | 117/300 [05:28<06:45,  2.21s/it]\n",
      " 39%|███▉      | 118/300 [05:30<06:26,  2.13s/it]\n",
      " 40%|███▉      | 119/300 [05:32<06:07,  2.03s/it]\n",
      " 40%|████      | 120/300 [05:38<09:37,  3.21s/it]\n",
      " 40%|████      | 121/300 [05:39<07:52,  2.64s/it]\n",
      " 41%|████      | 122/300 [05:39<05:39,  1.91s/it]\n",
      " 41%|████      | 123/300 [05:42<05:48,  1.97s/it]\n",
      " 41%|████▏     | 124/300 [05:46<08:13,  2.80s/it]\n",
      " 42%|████▏     | 125/300 [05:47<06:15,  2.14s/it]\n",
      " 42%|████▏     | 126/300 [05:49<06:17,  2.17s/it]\n",
      " 42%|████▏     | 127/300 [05:51<05:41,  1.97s/it]\n",
      " 43%|████▎     | 128/300 [05:56<08:22,  2.92s/it]\n",
      " 43%|████▎     | 129/300 [05:56<05:55,  2.08s/it]\n",
      " 43%|████▎     | 130/300 [05:57<05:29,  1.94s/it]\n",
      " 44%|████▎     | 131/300 [06:03<08:35,  3.05s/it]\n",
      " 44%|████▍     | 132/300 [06:04<06:24,  2.29s/it]\n",
      " 44%|████▍     | 133/300 [06:05<05:43,  2.06s/it]\n",
      " 45%|████▍     | 134/300 [06:06<04:44,  1.71s/it]\n",
      " 45%|████▌     | 135/300 [06:12<08:17,  3.01s/it]\n",
      " 45%|████▌     | 136/300 [06:14<07:30,  2.75s/it]\n",
      " 46%|████▌     | 137/300 [06:15<06:02,  2.22s/it]\n",
      " 46%|████▌     | 138/300 [06:18<06:14,  2.31s/it]\n",
      " 46%|████▋     | 139/300 [06:25<09:47,  3.65s/it]\n",
      " 47%|████▋     | 140/300 [06:27<08:44,  3.28s/it]\n",
      " 47%|████▋     | 141/300 [06:28<06:58,  2.63s/it]\n",
      " 47%|████▋     | 142/300 [06:29<05:53,  2.23s/it]\n",
      " 48%|████▊     | 143/300 [06:37<10:25,  3.99s/it]\n",
      " 48%|████▊     | 144/300 [06:40<09:08,  3.52s/it]\n",
      " 48%|████▊     | 145/300 [06:41<06:54,  2.67s/it]\n",
      " 49%|████▊     | 146/300 [06:42<05:53,  2.29s/it]\n",
      " 49%|████▉     | 147/300 [06:47<07:43,  3.03s/it]\n",
      " 49%|████▉     | 148/300 [06:47<05:54,  2.33s/it]\n",
      " 50%|████▉     | 149/300 [06:51<06:28,  2.57s/it]\n",
      " 50%|█████     | 150/300 [06:55<08:03,  3.22s/it]\n",
      " 50%|█████     | 151/300 [06:58<07:28,  3.01s/it]\n",
      " 51%|█████     | 152/300 [07:00<06:41,  2.71s/it]\n",
      " 51%|█████     | 153/300 [07:01<05:19,  2.17s/it]\n",
      " 51%|█████▏    | 154/300 [07:06<07:18,  3.01s/it]\n",
      " 52%|█████▏    | 155/300 [07:10<08:13,  3.41s/it]\n",
      " 52%|█████▏    | 156/300 [07:11<06:13,  2.60s/it]\n",
      " 52%|█████▏    | 157/300 [07:11<04:32,  1.91s/it]\n",
      " 53%|█████▎    | 158/300 [07:17<07:18,  3.09s/it]\n",
      " 53%|█████▎    | 159/300 [07:20<07:04,  3.01s/it]\n",
      " 53%|█████▎    | 160/300 [07:22<06:11,  2.65s/it]\n",
      " 54%|█████▎    | 161/300 [07:25<06:41,  2.89s/it]\n",
      " 54%|█████▍    | 162/300 [07:30<07:46,  3.38s/it]\n",
      " 54%|█████▍    | 163/300 [07:31<06:10,  2.70s/it]\n",
      " 55%|█████▍    | 164/300 [07:31<04:41,  2.07s/it]\n",
      " 55%|█████▌    | 165/300 [07:34<04:58,  2.21s/it]\n",
      " 55%|█████▌    | 166/300 [07:37<05:49,  2.61s/it]\n",
      " 56%|█████▌    | 167/300 [07:41<06:27,  2.91s/it]\n",
      " 56%|█████▌    | 168/300 [07:42<05:13,  2.37s/it]\n",
      " 56%|█████▋    | 169/300 [07:43<04:01,  1.84s/it]\n",
      " 57%|█████▋    | 170/300 [07:47<05:44,  2.65s/it]\n",
      " 57%|█████▋    | 171/300 [07:51<06:27,  3.01s/it]\n",
      " 57%|█████▋    | 172/300 [07:54<06:06,  2.86s/it]\n",
      " 58%|█████▊    | 173/300 [07:57<06:09,  2.91s/it]\n",
      " 58%|█████▊    | 174/300 [07:57<04:39,  2.22s/it]\n",
      " 58%|█████▊    | 175/300 [08:02<06:31,  3.13s/it]\n",
      " 59%|█████▊    | 176/300 [08:06<06:39,  3.22s/it]\n",
      " 59%|█████▉    | 177/300 [08:07<05:14,  2.56s/it]\n",
      " 59%|█████▉    | 178/300 [08:07<03:45,  1.85s/it]\n",
      " 60%|█████▉    | 179/300 [08:14<06:49,  3.38s/it]\n",
      " 60%|██████    | 180/300 [08:17<06:15,  3.13s/it]\n",
      " 60%|██████    | 181/300 [08:17<04:27,  2.25s/it]\n",
      " 61%|██████    | 182/300 [08:20<05:00,  2.54s/it]\n",
      " 61%|██████    | 183/300 [08:22<04:39,  2.39s/it]\n",
      " 61%|██████▏   | 184/300 [08:25<04:59,  2.58s/it]\n",
      " 62%|██████▏   | 185/300 [08:27<04:44,  2.47s/it]\n",
      " 62%|██████▏   | 186/300 [08:29<04:08,  2.18s/it]\n",
      " 62%|██████▏   | 187/300 [08:33<04:59,  2.65s/it]\n",
      " 63%|██████▎   | 188/300 [08:34<04:04,  2.19s/it]\n",
      " 63%|██████▎   | 189/300 [08:39<05:48,  3.14s/it]\n",
      " 63%|██████▎   | 190/300 [08:41<05:21,  2.92s/it]\n",
      " 64%|██████▎   | 191/300 [08:43<04:32,  2.50s/it]\n",
      " 64%|██████▍   | 192/300 [08:45<04:20,  2.42s/it]\n",
      " 64%|██████▍   | 193/300 [08:48<04:41,  2.63s/it]\n",
      " 65%|██████▍   | 194/300 [08:53<05:49,  3.29s/it]\n",
      " 65%|██████▌   | 195/300 [08:53<04:05,  2.34s/it]\n",
      " 65%|██████▌   | 196/300 [08:55<03:49,  2.21s/it]\n",
      " 66%|██████▌   | 197/300 [09:03<06:33,  3.82s/it]\n",
      " 66%|██████▌   | 198/300 [09:03<04:57,  2.91s/it]\n",
      " 67%|██████▋   | 200/300 [09:06<03:30,  2.10s/it]\n",
      " 67%|██████▋   | 201/300 [09:13<05:30,  3.33s/it]\n",
      " 67%|██████▋   | 202/300 [09:15<04:55,  3.02s/it]\n",
      " 68%|██████▊   | 203/300 [09:17<04:20,  2.69s/it]\n",
      " 68%|██████▊   | 204/300 [09:18<03:24,  2.13s/it]\n",
      " 68%|██████▊   | 205/300 [09:22<04:30,  2.85s/it]\n",
      " 69%|██████▊   | 206/300 [09:23<03:24,  2.17s/it]\n",
      " 69%|██████▉   | 207/300 [09:29<05:07,  3.31s/it]\n",
      " 69%|██████▉   | 208/300 [09:30<03:56,  2.57s/it]\n",
      " 70%|██████▉   | 209/300 [09:30<02:58,  1.96s/it]\n",
      " 70%|███████   | 210/300 [09:30<02:09,  1.44s/it]\n",
      " 70%|███████   | 211/300 [09:38<04:55,  3.33s/it]\n",
      " 71%|███████   | 212/300 [09:39<03:57,  2.69s/it]\n",
      " 71%|███████   | 213/300 [09:41<03:42,  2.55s/it]\n",
      " 71%|███████▏  | 214/300 [09:43<03:02,  2.12s/it]\n",
      " 72%|███████▏  | 215/300 [09:47<04:12,  2.97s/it]\n",
      " 72%|███████▏  | 216/300 [09:51<04:10,  2.98s/it]\n",
      " 72%|███████▏  | 217/300 [09:53<03:43,  2.70s/it]\n",
      " 73%|███████▎  | 218/300 [09:53<02:47,  2.04s/it]\n",
      " 73%|███████▎  | 219/300 [09:58<04:05,  3.03s/it]\n",
      " 73%|███████▎  | 220/300 [09:59<03:09,  2.36s/it]\n",
      " 74%|███████▎  | 221/300 [10:01<03:03,  2.32s/it]\n",
      " 74%|███████▍  | 222/300 [10:09<04:54,  3.77s/it]\n",
      " 74%|███████▍  | 223/300 [10:09<03:37,  2.82s/it]\n",
      " 75%|███████▍  | 224/300 [10:13<03:46,  2.98s/it]\n",
      " 75%|███████▌  | 226/300 [10:16<03:02,  2.46s/it]\n",
      " 76%|███████▌  | 227/300 [10:20<03:21,  2.75s/it]\n",
      " 76%|███████▌  | 228/300 [10:20<02:37,  2.19s/it]\n",
      " 76%|███████▋  | 229/300 [10:24<03:09,  2.67s/it]\n",
      " 77%|███████▋  | 230/300 [10:25<02:26,  2.09s/it]\n",
      " 77%|███████▋  | 231/300 [10:29<02:52,  2.50s/it]\n",
      " 77%|███████▋  | 232/300 [10:30<02:36,  2.30s/it]\n",
      " 78%|███████▊  | 233/300 [10:37<04:03,  3.64s/it]\n",
      " 78%|███████▊  | 234/300 [10:39<03:30,  3.19s/it]\n",
      " 78%|███████▊  | 235/300 [10:41<03:04,  2.84s/it]\n",
      " 79%|███████▊  | 236/300 [10:42<02:23,  2.24s/it]\n",
      " 79%|███████▉  | 237/300 [10:50<03:57,  3.77s/it]\n",
      " 79%|███████▉  | 238/300 [10:50<02:55,  2.82s/it]\n",
      " 80%|███████▉  | 239/300 [10:51<02:13,  2.19s/it]\n",
      " 80%|████████  | 240/300 [10:52<01:48,  1.81s/it]\n",
      " 80%|████████  | 241/300 [10:58<03:05,  3.14s/it]\n",
      " 81%|████████  | 242/300 [11:01<02:53,  2.98s/it]\n",
      " 81%|████████  | 243/300 [11:01<02:00,  2.12s/it]\n",
      " 81%|████████▏ | 244/300 [11:05<02:29,  2.66s/it]\n",
      " 82%|████████▏ | 245/300 [11:08<02:29,  2.71s/it]\n",
      " 82%|████████▏ | 246/300 [11:10<02:21,  2.63s/it]\n",
      " 82%|████████▏ | 247/300 [11:11<01:55,  2.17s/it]\n",
      " 83%|████████▎ | 248/300 [11:14<02:10,  2.52s/it]\n",
      " 83%|████████▎ | 249/300 [11:20<02:53,  3.40s/it]\n",
      " 84%|████████▎ | 251/300 [11:21<01:41,  2.06s/it]\n",
      " 84%|████████▍ | 252/300 [11:28<02:42,  3.38s/it]\n",
      " 84%|████████▍ | 253/300 [11:29<02:02,  2.60s/it]\n",
      " 85%|████████▍ | 254/300 [11:33<02:25,  3.16s/it]\n",
      " 85%|████████▌ | 255/300 [11:34<01:48,  2.41s/it]\n",
      " 85%|████████▌ | 256/300 [11:38<02:09,  2.93s/it]\n",
      " 86%|████████▌ | 257/300 [11:43<02:30,  3.49s/it]\n",
      " 86%|████████▌ | 258/300 [11:44<01:59,  2.85s/it]\n",
      " 86%|████████▋ | 259/300 [11:45<01:37,  2.37s/it]\n",
      " 87%|████████▋ | 260/300 [11:51<02:11,  3.28s/it]\n",
      " 87%|████████▋ | 261/300 [11:54<02:03,  3.18s/it]\n",
      " 87%|████████▋ | 262/300 [11:55<01:40,  2.65s/it]\n",
      " 88%|████████▊ | 263/300 [11:56<01:17,  2.10s/it]\n",
      " 88%|████████▊ | 264/300 [12:00<01:35,  2.65s/it]\n",
      " 88%|████████▊ | 265/300 [12:01<01:14,  2.13s/it]\n",
      " 89%|████████▊ | 266/300 [12:03<01:11,  2.10s/it]\n",
      " 89%|████████▉ | 267/300 [12:05<01:10,  2.13s/it]\n",
      " 89%|████████▉ | 268/300 [12:08<01:12,  2.28s/it]\n",
      " 90%|████████▉ | 269/300 [12:11<01:21,  2.63s/it]\n",
      " 90%|█████████ | 270/300 [12:12<01:05,  2.17s/it]\n",
      " 90%|█████████ | 271/300 [12:13<00:53,  1.85s/it]\n",
      " 91%|█████████ | 272/300 [12:20<01:28,  3.17s/it]\n",
      " 91%|█████████ | 273/300 [12:22<01:17,  2.89s/it]\n",
      " 91%|█████████▏| 274/300 [12:23<01:02,  2.38s/it]\n",
      " 92%|█████████▏| 275/300 [12:25<00:54,  2.18s/it]\n",
      " 92%|█████████▏| 276/300 [12:30<01:12,  3.01s/it]\n",
      " 92%|█████████▏| 277/300 [12:31<00:55,  2.41s/it]\n",
      " 93%|█████████▎| 278/300 [12:33<00:53,  2.41s/it]\n",
      " 93%|█████████▎| 279/300 [12:36<00:53,  2.57s/it]\n",
      " 93%|█████████▎| 280/300 [12:38<00:50,  2.52s/it]\n",
      " 94%|█████████▎| 281/300 [12:41<00:50,  2.65s/it]\n",
      " 94%|█████████▍| 282/300 [12:45<00:54,  3.00s/it]\n",
      " 94%|█████████▍| 283/300 [12:48<00:47,  2.80s/it]\n",
      " 95%|█████████▍| 284/300 [12:49<00:36,  2.26s/it]\n",
      " 95%|█████████▌| 285/300 [12:49<00:25,  1.70s/it]\n",
      " 95%|█████████▌| 286/300 [12:58<00:53,  3.83s/it]\n",
      " 96%|█████████▌| 287/300 [12:58<00:37,  2.89s/it]\n",
      " 96%|█████████▌| 288/300 [13:01<00:31,  2.66s/it]\n",
      " 96%|█████████▋| 289/300 [13:02<00:23,  2.16s/it]\n",
      " 97%|█████████▋| 290/300 [13:07<00:30,  3.09s/it]\n",
      " 97%|█████████▋| 291/300 [13:08<00:21,  2.40s/it]\n",
      " 97%|█████████▋| 292/300 [13:09<00:15,  1.99s/it]\n",
      " 98%|█████████▊| 293/300 [13:10<00:11,  1.66s/it]\n",
      " 98%|█████████▊| 294/300 [13:18<00:22,  3.71s/it]\n",
      " 99%|█████████▊| 296/300 [13:20<00:09,  2.35s/it]\n",
      " 99%|█████████▉| 297/300 [13:20<00:05,  1.91s/it]\n",
      " 99%|█████████▉| 298/300 [13:23<00:04,  2.15s/it]\n",
      "100%|█████████▉| 299/300 [13:25<00:02,  2.25s/it]\n",
      "100%|██████████| 300/300 [13:30<00:00,  2.95s/it]\n",
      "100%|██████████| 300/300 [13:30<00:00,  2.70s/it]\n"
     ]
    }
   ],
   "source": [
    "!nnUNetv2_preprocess -d 1 \\\n",
    "                     -plans_name nnUNetResEncUNetLPlans \\\n",
    "                     -c 3d_fullres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zI_epHgDWlRv"
   },
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 6390,
     "status": "ok",
     "timestamp": 1741654606091,
     "user": {
      "displayName": "LAB AI",
      "userId": "05090763676444143877"
     },
     "user_tz": -480
    },
    "id": "MDfyGv-r-a5q",
    "outputId": "1a0f575b-300b-461d-b380-47349414b92c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: nnUNetv2_train [-h] [-tr TR] [-p P]\n",
      "                      [-pretrained_weights PRETRAINED_WEIGHTS]\n",
      "                      [-num_gpus NUM_GPUS] [--npz] [--c] [--val] [--val_best]\n",
      "                      [--disable_checkpointing] [-device DEVICE]\n",
      "                      dataset_name_or_id configuration fold\n",
      "\n",
      "positional arguments:\n",
      "  dataset_name_or_id    Dataset name or ID to train with\n",
      "  configuration         Configuration that should be trained\n",
      "  fold                  Fold of the 5-fold cross-validation. Should be an int\n",
      "                        between 0 and 4.\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  -tr TR                [OPTIONAL] Use this flag to specify a custom trainer.\n",
      "                        Default: nnUNetTrainer\n",
      "  -p P                  [OPTIONAL] Use this flag to specify a custom plans\n",
      "                        identifier. Default: nnUNetPlans\n",
      "  -pretrained_weights PRETRAINED_WEIGHTS\n",
      "                        [OPTIONAL] path to nnU-Net checkpoint file to be used\n",
      "                        as pretrained model. Will only be used when actually\n",
      "                        training. Beta. Use with caution.\n",
      "  -num_gpus NUM_GPUS    Specify the number of GPUs to use for training\n",
      "  --npz                 [OPTIONAL] Save softmax predictions from final\n",
      "                        validation as npz files (in addition to predicted\n",
      "                        segmentations). Needed for finding the best ensemble.\n",
      "  --c                   [OPTIONAL] Continue training from latest checkpoint\n",
      "  --val                 [OPTIONAL] Set this flag to only run the validation.\n",
      "                        Requires training to have finished.\n",
      "  --val_best            [OPTIONAL] If set, the validation will be performed\n",
      "                        with the checkpoint_best instead of checkpoint_final.\n",
      "                        NOT COMPATIBLE with --disable_checkpointing! WARNING:\n",
      "                        This will use the same 'validation' folder as the\n",
      "                        regular validation with no way of distinguishing the\n",
      "                        two!\n",
      "  --disable_checkpointing\n",
      "                        [OPTIONAL] Set this flag to disable checkpointing.\n",
      "                        Ideal for testing things out and you dont want to\n",
      "                        flood your hard drive with checkpoints.\n",
      "  -device DEVICE        Use this to set the device the training should run\n",
      "                        with. Available options are 'cuda' (GPU), 'cpu' (CPU)\n",
      "                        and 'mps' (Apple M1/M2). Do NOT use this to set which\n",
      "                        GPU ID! Use CUDA_VISIBLE_DEVICES=X nnUNetv2_train\n",
      "                        [...] instead!\n"
     ]
    }
   ],
   "source": [
    "!nnUNetv2_train -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 17457195,
     "status": "ok",
     "timestamp": 1742283267914,
     "user": {
      "displayName": "LAB AI",
      "userId": "05090763676444143877"
     },
     "user_tz": -480
    },
    "id": "z8dWK7mOlxcs",
    "outputId": "d1f60233-b00c-4614-c78f-3a28afd5732b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "\n",
      "#######################################################################\n",
      "Please cite the following paper when using nnU-Net:\n",
      "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
      "#######################################################################\n",
      "\n",
      "2025-05-16 14:18:21.412077: do_dummy_2d_data_aug: True\n",
      "2025-05-16 14:18:21.415077: Using splits from existing split file: C:\\Users\\CUTY\\Desktop\\AOR\\nnU_Base\\nnUNet_preprocessed\\Dataset001_MYTASK\\splits_final.json\n",
      "2025-05-16 14:18:21.425078: The split file contains 5 splits.\n",
      "2025-05-16 14:18:21.435081: Desired fold for training: 1\n",
      "2025-05-16 14:18:21.442080: This split has 240 training and 60 validation cases.\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "\n",
      "This is the configuration used by this training:\n",
      "Configuration name: 3d_fullres\n",
      " {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 1, 'patch_size': [56, 320, 256], 'median_image_size_in_voxels': [94.0, 512.0, 512.0], 'spacing': [5.0, 0.68359375, 0.68359375], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.ResidualEncoderUNet', 'arch_kwargs': {'n_stages': 7, 'features_per_stage': [32, 64, 128, 256, 320, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[1, 3, 3], [1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [1, 2, 2], [1, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_blocks_per_stage': [1, 3, 4, 6, 6, 6, 6], 'n_conv_per_stage_decoder': [1, 1, 1, 1, 1, 1], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} \n",
      "\n",
      "These are the global plan.json settings:\n",
      " {'dataset_name': 'Dataset001_MYTASK', 'plans_name': 'nnUNetResEncUNetLPlans', 'original_median_spacing_after_transp': [5.0, 0.68359375, 0.68359375], 'original_median_shape_after_transp': [94, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'nnUNetPlannerResEncL', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 1194.0, 'mean': 35.515421415421415, 'median': 42.0, 'min': -1022.0, 'percentile_00_5': -111.0, 'percentile_99_5': 141.0, 'std': 54.29036316376703}}} \n",
      "\n",
      "2025-05-16 14:18:34.738006: Unable to plot network architecture:\n",
      "2025-05-16 14:18:34.755565: No module named 'hiddenlayer'\n",
      "2025-05-16 14:18:34.814349: \n",
      "2025-05-16 14:18:34.837350: Epoch 0\n",
      "2025-05-16 14:18:34.859351: Current learning rate: 0.01\n",
      "2025-05-16 14:25:59.556670: train_loss 0.0137\n",
      "2025-05-16 14:25:59.556670: val_loss -0.0465\n",
      "2025-05-16 14:25:59.578671: Pseudo dice [np.float32(0.0)]\n",
      "2025-05-16 14:25:59.586671: Epoch time: 444.75 s\n",
      "2025-05-16 14:25:59.595791: Yayy! New best EMA pseudo Dice: 0.0\n",
      "2025-05-16 14:26:05.086658: \n",
      "2025-05-16 14:26:05.097168: Epoch 1\n",
      "2025-05-16 14:26:05.107169: Current learning rate: 0.00999\n",
      "2025-05-16 14:33:03.372887: train_loss -0.0554\n",
      "2025-05-16 14:33:03.373886: val_loss -0.0552\n",
      "2025-05-16 14:33:03.389886: Pseudo dice [np.float32(0.0)]\n",
      "2025-05-16 14:33:03.397886: Epoch time: 418.29 s\n",
      "2025-05-16 14:33:04.319906: \n",
      "2025-05-16 14:33:04.330908: Epoch 2\n",
      "2025-05-16 14:33:04.338908: Current learning rate: 0.00998\n",
      "2025-05-16 14:39:56.321798: train_loss -0.0537\n",
      "2025-05-16 14:39:56.322798: val_loss -0.0663\n",
      "2025-05-16 14:39:56.332799: Pseudo dice [np.float32(0.0)]\n",
      "2025-05-16 14:39:56.341799: Epoch time: 412.0 s\n",
      "2025-05-16 14:39:57.278648: \n",
      "2025-05-16 14:39:57.288656: Epoch 3\n",
      "2025-05-16 14:39:57.296510: Current learning rate: 0.00997\n",
      "2025-05-16 14:46:50.385144: train_loss -0.0593\n",
      "2025-05-16 14:46:50.386194: val_loss -0.0594\n",
      "2025-05-16 14:46:50.396159: Pseudo dice [np.float32(0.0)]\n",
      "2025-05-16 14:46:50.404005: Epoch time: 413.11 s\n",
      "2025-05-16 14:46:51.308284: \n",
      "2025-05-16 14:46:51.318063: Epoch 4\n",
      "2025-05-16 14:46:51.325206: Current learning rate: 0.00996\n",
      "2025-05-16 14:53:44.747753: train_loss -0.0603\n",
      "2025-05-16 14:53:44.747753: val_loss -0.0571\n",
      "2025-05-16 14:53:44.758754: Pseudo dice [np.float32(0.0)]\n",
      "2025-05-16 14:53:44.766754: Epoch time: 413.44 s\n",
      "2025-05-16 14:53:45.720193: \n",
      "2025-05-16 14:53:45.729971: Epoch 5\n",
      "2025-05-16 14:53:45.738207: Current learning rate: 0.00995\n",
      "2025-05-16 15:00:40.650321: train_loss -0.0608\n",
      "2025-05-16 15:00:40.650837: val_loss -0.0698\n",
      "2025-05-16 15:00:40.661836: Pseudo dice [np.float32(0.0)]\n",
      "2025-05-16 15:00:40.669527: Epoch time: 414.93 s\n",
      "2025-05-16 15:00:41.557631: \n",
      "2025-05-16 15:00:41.567636: Epoch 6\n",
      "2025-05-16 15:00:41.576003: Current learning rate: 0.00995\n",
      "2025-05-16 15:07:35.877236: train_loss -0.0655\n",
      "2025-05-16 15:07:35.887329: val_loss -0.068\n",
      "2025-05-16 15:07:35.896408: Pseudo dice [np.float32(0.0)]\n",
      "2025-05-16 15:07:35.906017: Epoch time: 414.32 s\n",
      "2025-05-16 15:07:36.871663: \n",
      "2025-05-16 15:07:36.888622: Epoch 7\n",
      "2025-05-16 15:07:36.897769: Current learning rate: 0.00994\n",
      "2025-05-16 15:14:30.876075: train_loss -0.0669\n",
      "2025-05-16 15:14:30.887664: val_loss -0.0652\n",
      "2025-05-16 15:14:30.896665: Pseudo dice [np.float32(0.0)]\n",
      "2025-05-16 15:14:30.904664: Epoch time: 414.01 s\n",
      "2025-05-16 15:14:32.536978: \n",
      "2025-05-16 15:14:32.546956: Epoch 8\n",
      "2025-05-16 15:14:32.555970: Current learning rate: 0.00993\n",
      "2025-05-16 15:21:27.841547: train_loss -0.0681\n",
      "2025-05-16 15:21:27.852873: val_loss -0.0683\n",
      "2025-05-16 15:21:27.860775: Pseudo dice [np.float32(0.0)]\n",
      "2025-05-16 15:21:27.869947: Epoch time: 415.31 s\n",
      "2025-05-16 15:21:28.783105: \n",
      "2025-05-16 15:21:28.793120: Epoch 9\n",
      "2025-05-16 15:21:28.802561: Current learning rate: 0.00992\n",
      "2025-05-16 15:28:24.478680: train_loss -0.0751\n",
      "2025-05-16 15:28:24.490835: val_loss -0.0773\n",
      "2025-05-16 15:28:24.499861: Pseudo dice [np.float32(0.0)]\n",
      "2025-05-16 15:28:24.508488: Epoch time: 415.7 s\n",
      "2025-05-16 15:28:25.382351: \n",
      "2025-05-16 15:28:25.392325: Epoch 10\n",
      "2025-05-16 15:28:25.400689: Current learning rate: 0.00991\n",
      "2025-05-16 15:35:18.504230: train_loss -0.0765\n",
      "2025-05-16 15:35:18.516937: val_loss -0.0657\n",
      "2025-05-16 15:35:18.525895: Pseudo dice [np.float32(0.0)]\n",
      "2025-05-16 15:35:18.533949: Epoch time: 413.12 s\n",
      "2025-05-16 15:35:19.452317: \n",
      "2025-05-16 15:35:19.463478: Epoch 11\n",
      "2025-05-16 15:35:19.472467: Current learning rate: 0.0099\n",
      "2025-05-16 15:42:12.842826: train_loss -0.0629\n",
      "2025-05-16 15:42:12.855669: val_loss -0.0725\n",
      "2025-05-16 15:42:12.865284: Pseudo dice [np.float32(0.0)]\n",
      "2025-05-16 15:42:12.874370: Epoch time: 413.39 s\n",
      "2025-05-16 15:42:13.764621: \n",
      "2025-05-16 15:42:13.774344: Epoch 12\n",
      "2025-05-16 15:42:13.782995: Current learning rate: 0.00989\n",
      "2025-05-16 15:49:09.463392: train_loss -0.0754\n",
      "2025-05-16 15:49:09.473274: val_loss -0.0541\n",
      "2025-05-16 15:49:09.482861: Pseudo dice [np.float32(0.0)]\n",
      "2025-05-16 15:49:09.491516: Epoch time: 415.7 s\n",
      "2025-05-16 15:49:10.386203: \n",
      "2025-05-16 15:49:10.395261: Epoch 13\n",
      "2025-05-16 15:49:10.402708: Current learning rate: 0.00988\n",
      "2025-05-16 15:56:06.218627: train_loss -0.057\n",
      "2025-05-16 15:56:06.228827: val_loss -0.0638\n",
      "2025-05-16 15:56:06.237710: Pseudo dice [np.float32(0.0)]\n",
      "2025-05-16 15:56:06.246623: Epoch time: 415.84 s\n",
      "2025-05-16 15:56:07.164578: \n",
      "2025-05-16 15:56:07.174858: Epoch 14\n",
      "2025-05-16 15:56:07.182896: Current learning rate: 0.00987\n",
      "2025-05-16 16:03:02.670849: train_loss -0.0538\n",
      "2025-05-16 16:03:02.683146: val_loss -0.0638\n",
      "2025-05-16 16:03:02.691604: Pseudo dice [np.float32(0.0)]\n",
      "2025-05-16 16:03:02.700136: Epoch time: 415.51 s\n",
      "2025-05-16 16:03:03.610683: \n",
      "2025-05-16 16:03:03.619736: Epoch 15\n",
      "2025-05-16 16:03:03.628233: Current learning rate: 0.00986\n",
      "2025-05-16 16:09:58.983995: train_loss -0.0591\n",
      "2025-05-16 16:09:58.994077: val_loss -0.0686\n",
      "2025-05-16 16:09:59.002548: Pseudo dice [np.float32(0.0)]\n",
      "2025-05-16 16:09:59.011639: Epoch time: 415.38 s\n",
      "2025-05-16 16:09:59.947713: \n",
      "2025-05-16 16:09:59.957796: Epoch 16\n",
      "2025-05-16 16:09:59.966311: Current learning rate: 0.00986\n",
      "2025-05-16 16:16:53.087822: train_loss -0.0746\n",
      "2025-05-16 16:16:53.099571: val_loss -0.0746\n",
      "2025-05-16 16:16:53.108057: Pseudo dice [np.float32(0.0587)]\n",
      "2025-05-16 16:16:53.117125: Epoch time: 413.14 s\n",
      "2025-05-16 16:16:53.125617: Yayy! New best EMA pseudo Dice: 0.005900000222027302\n",
      "2025-05-16 16:16:56.588392: \n",
      "2025-05-16 16:16:56.599599: Epoch 17\n",
      "2025-05-16 16:16:56.606495: Current learning rate: 0.00985\n",
      "2025-05-16 16:23:51.244863: train_loss -0.075\n",
      "2025-05-16 16:23:51.245382: val_loss -0.088\n",
      "2025-05-16 16:23:51.258062: Pseudo dice [np.float32(0.0851)]\n",
      "2025-05-16 16:23:51.267548: Epoch time: 414.66 s\n",
      "2025-05-16 16:23:51.275421: Yayy! New best EMA pseudo Dice: 0.013799999840557575\n",
      "2025-05-16 16:23:54.846954: \n",
      "2025-05-16 16:23:54.856913: Epoch 18\n",
      "2025-05-16 16:23:54.865880: Current learning rate: 0.00984\n",
      "2025-05-16 16:30:48.792238: train_loss -0.0744\n",
      "2025-05-16 16:30:48.803421: val_loss -0.1038\n",
      "2025-05-16 16:30:48.811448: Pseudo dice [np.float32(0.1499)]\n",
      "2025-05-16 16:30:48.820465: Epoch time: 413.95 s\n",
      "2025-05-16 16:30:48.828463: Yayy! New best EMA pseudo Dice: 0.027400000020861626\n",
      "2025-05-16 16:30:51.665320: \n",
      "2025-05-16 16:30:51.674842: Epoch 19\n",
      "2025-05-16 16:30:51.683659: Current learning rate: 0.00983\n",
      "2025-05-16 16:37:45.837460: train_loss -0.0773\n",
      "2025-05-16 16:37:45.849237: val_loss -0.0858\n",
      "2025-05-16 16:37:45.858068: Pseudo dice [np.float32(0.0581)]\n",
      "2025-05-16 16:37:45.866310: Epoch time: 414.17 s\n",
      "2025-05-16 16:37:45.874057: Yayy! New best EMA pseudo Dice: 0.030500000342726707\n",
      "2025-05-16 16:37:49.766839: \n",
      "2025-05-16 16:37:49.776912: Epoch 20\n",
      "2025-05-16 16:37:49.785896: Current learning rate: 0.00982\n",
      "2025-05-16 16:44:43.195807: train_loss -0.0817\n",
      "2025-05-16 16:44:43.205806: val_loss -0.081\n",
      "2025-05-16 16:44:43.214805: Pseudo dice [np.float32(0.0552)]\n",
      "2025-05-16 16:44:43.222923: Epoch time: 413.43 s\n",
      "2025-05-16 16:44:43.231569: Yayy! New best EMA pseudo Dice: 0.03290000185370445\n",
      "2025-05-16 16:44:46.556247: \n",
      "2025-05-16 16:44:46.565693: Epoch 21\n",
      "2025-05-16 16:44:46.573869: Current learning rate: 0.00981\n",
      "2025-05-16 16:51:40.262423: train_loss -0.0806\n",
      "2025-05-16 16:51:40.272441: val_loss -0.0675\n",
      "2025-05-16 16:51:40.280457: Pseudo dice [np.float32(0.0345)]\n",
      "2025-05-16 16:51:40.288455: Epoch time: 413.71 s\n",
      "2025-05-16 16:51:40.296457: Yayy! New best EMA pseudo Dice: 0.03310000151395798\n",
      "2025-05-16 16:51:43.776043: \n",
      "2025-05-16 16:51:43.785053: Epoch 22\n",
      "2025-05-16 16:51:43.793726: Current learning rate: 0.0098\n",
      "2025-05-16 16:58:40.297277: train_loss -0.0813\n",
      "2025-05-16 16:58:40.307148: val_loss -0.061\n",
      "2025-05-16 16:58:40.316674: Pseudo dice [np.float32(0.0)]\n",
      "2025-05-16 16:58:40.325139: Epoch time: 416.52 s\n",
      "2025-05-16 16:58:41.231774: \n",
      "2025-05-16 16:58:41.241215: Epoch 23\n",
      "2025-05-16 16:58:41.250147: Current learning rate: 0.00979\n",
      "2025-05-16 17:05:35.482573: train_loss -0.0601\n",
      "2025-05-16 17:05:35.492566: val_loss -0.0571\n",
      "2025-05-16 17:05:35.501586: Pseudo dice [np.float32(0.0)]\n",
      "2025-05-16 17:05:35.509995: Epoch time: 414.25 s\n",
      "2025-05-16 17:05:36.394885: \n",
      "2025-05-16 17:05:36.404346: Epoch 24\n",
      "2025-05-16 17:05:36.411374: Current learning rate: 0.00978\n",
      "2025-05-16 17:12:30.824091: train_loss -0.06\n",
      "2025-05-16 17:12:30.835299: val_loss -0.0801\n",
      "2025-05-16 17:12:30.843929: Pseudo dice [np.float32(0.0332)]\n",
      "2025-05-16 17:12:30.852679: Epoch time: 414.43 s\n",
      "2025-05-16 17:12:31.754369: \n",
      "2025-05-16 17:12:31.763873: Epoch 25\n",
      "2025-05-16 17:12:31.772854: Current learning rate: 0.00977\n",
      "2025-05-16 17:19:24.915021: train_loss -0.0734\n",
      "2025-05-16 17:19:24.927228: val_loss -0.0832\n",
      "2025-05-16 17:19:24.935951: Pseudo dice [np.float32(0.1213)]\n",
      "2025-05-16 17:19:24.944664: Epoch time: 413.16 s\n",
      "2025-05-16 17:19:24.953691: Yayy! New best EMA pseudo Dice: 0.03680000081658363\n",
      "2025-05-16 17:19:28.558854: \n",
      "2025-05-16 17:19:28.568014: Epoch 26\n",
      "2025-05-16 17:19:28.576725: Current learning rate: 0.00977\n",
      "2025-05-16 17:26:25.516237: train_loss -0.0668\n",
      "2025-05-16 17:26:25.517238: val_loss -0.0777\n",
      "2025-05-16 17:26:25.528238: Pseudo dice [np.float32(0.0328)]\n",
      "2025-05-16 17:26:25.537237: Epoch time: 416.96 s\n",
      "2025-05-16 17:26:26.644376: \n",
      "2025-05-16 17:26:26.654684: Epoch 27\n",
      "2025-05-16 17:26:26.663259: Current learning rate: 0.00976\n",
      "2025-05-16 17:33:24.668205: train_loss -0.0742\n",
      "2025-05-16 17:33:24.668760: val_loss -0.0992\n",
      "2025-05-16 17:33:24.678170: Pseudo dice [np.float32(0.0756)]\n",
      "2025-05-16 17:33:24.688162: Epoch time: 418.03 s\n",
      "2025-05-16 17:33:24.697156: Yayy! New best EMA pseudo Dice: 0.040300000458955765\n",
      "2025-05-16 17:33:28.207515: \n",
      "2025-05-16 17:33:28.217506: Epoch 28\n",
      "2025-05-16 17:33:28.226460: Current learning rate: 0.00975\n",
      "2025-05-16 17:40:15.094173: train_loss -0.0834\n",
      "2025-05-16 17:40:15.104173: val_loss -0.0951\n",
      "2025-05-16 17:40:15.112174: Pseudo dice [np.float32(0.0793)]\n",
      "2025-05-16 17:40:15.121173: Epoch time: 406.89 s\n",
      "2025-05-16 17:40:15.129174: Yayy! New best EMA pseudo Dice: 0.044199999421834946\n",
      "2025-05-16 17:40:18.798356: \n",
      "2025-05-16 17:40:18.808392: Epoch 29\n",
      "2025-05-16 17:40:18.817340: Current learning rate: 0.00974\n",
      "2025-05-16 17:47:02.007930: train_loss -0.0889\n",
      "2025-05-16 17:47:02.008930: val_loss -0.0955\n",
      "2025-05-16 17:47:02.019930: Pseudo dice [np.float32(0.0545)]\n",
      "2025-05-16 17:47:02.027942: Epoch time: 403.21 s\n",
      "2025-05-16 17:47:02.037605: Yayy! New best EMA pseudo Dice: 0.04529999941587448\n",
      "2025-05-16 17:47:05.068383: \n",
      "2025-05-16 17:47:05.077384: Epoch 30\n",
      "2025-05-16 17:47:05.085384: Current learning rate: 0.00973\n",
      "2025-05-16 17:53:48.115562: train_loss -0.079\n",
      "2025-05-16 17:53:48.115562: val_loss -0.0714\n",
      "2025-05-16 17:53:48.127564: Pseudo dice [np.float32(0.0)]\n",
      "2025-05-16 17:53:48.136562: Epoch time: 403.05 s\n",
      "2025-05-16 17:53:49.059278: \n",
      "2025-05-16 17:53:49.069279: Epoch 31\n",
      "2025-05-16 17:53:49.077278: Current learning rate: 0.00972\n",
      "2025-05-16 18:00:30.011559: train_loss -0.0592\n",
      "2025-05-16 18:00:30.011559: val_loss -0.0666\n",
      "2025-05-16 18:00:30.021561: Pseudo dice [np.float32(0.0)]\n",
      "2025-05-16 18:00:30.028559: Epoch time: 400.96 s\n",
      "2025-05-16 18:00:30.957172: \n",
      "2025-05-16 18:00:30.966164: Epoch 32\n",
      "2025-05-16 18:00:30.974665: Current learning rate: 0.00971\n",
      "2025-05-16 18:07:19.866278: train_loss -0.0545\n",
      "2025-05-16 18:07:19.875092: val_loss -0.0585\n",
      "2025-05-16 18:07:19.883052: Pseudo dice [np.float32(0.0)]\n",
      "2025-05-16 18:07:19.890078: Epoch time: 408.91 s\n",
      "2025-05-16 18:07:21.382599: \n",
      "2025-05-16 18:07:21.391667: Epoch 33\n",
      "2025-05-16 18:07:21.400721: Current learning rate: 0.0097\n",
      "Exception in background worker 11:\n",
      " Exception in background worker 9:\n",
      "Unable to allocate 29.5 MiB for an array with shape (1, 56, 376, 367) and data type float32\n",
      " Unable to allocate 30.2 MiB for an array with shape (1, 1, 56, 376, 376) and data type float32\n",
      "Exception in background worker 2:\n",
      " Unable to allocate 30.2 MiB for an array with shape (1, 1, 56, 376, 376) and data type float32\n",
      "Exception in background worker 1:\n",
      " Unable to allocate 30.2 MiB for an array with shape (1, 1, 56, 376, 376) and data type float32\n",
      "Exception in background worker 10:\n",
      " Unable to allocate 30.2 MiB for an array with shape (1, 1, 56, 376, 376) and data type float32\n",
      "Exception in background worker 4:\n",
      " Unable to allocate 30.2 MiB for an array with shape (1, 1, 56, 376, 376) and data type float32\n",
      "Exception in background worker 8:\n",
      " Unable to allocate 30.2 MiB for an array with shape (1, 1, 56, 376, 376) and data type float32\n",
      "Exception in background worker 7:\n",
      " Unable to allocate 30.2 MiB for an array with shape (1, 1, 56, 376, 376) and data type float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\batchgenerators\\dataloading\\nondet_multi_threaded_augmenter.py\", line 53, in producer\n",
      "    item = next(data_loader)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\batchgenerators\\dataloading\\data_loader.py\", line 126, in __next__\n",
      "    return self.generate_train_batch()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\nnunetv2\\training\\dataloading\\data_loader.py\", line 170, in generate_train_batch\n",
      "    data_all = np.zeros(self.data_shape, dtype=np.float32)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "numpy._core._exceptions._ArrayMemoryError: Unable to allocate 30.2 MiB for an array with shape (1, 1, 56, 376, 376) and data type float32\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\batchgenerators\\dataloading\\nondet_multi_threaded_augmenter.py\", line 53, in producer\n",
      "    item = next(data_loader)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\batchgenerators\\dataloading\\data_loader.py\", line 126, in __next__\n",
      "    return self.generate_train_batch()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\nnunetv2\\training\\dataloading\\data_loader.py\", line 170, in generate_train_batch\n",
      "    data_all = np.zeros(self.data_shape, dtype=np.float32)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\batchgenerators\\dataloading\\nondet_multi_threaded_augmenter.py\", line 53, in producer\n",
      "    item = next(data_loader)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\batchgenerators\\dataloading\\data_loader.py\", line 126, in __next__\n",
      "    return self.generate_train_batch()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\nnunetv2\\training\\dataloading\\data_loader.py\", line 170, in generate_train_batch\n",
      "    data_all = np.zeros(self.data_shape, dtype=np.float32)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "numpy._core._exceptions._ArrayMemoryError: Unable to allocate 30.2 MiB for an array with shape (1, 1, 56, 376, 376) and data type float32\n",
      "numpy._core._exceptions._ArrayMemoryError: Unable to allocate 30.2 MiB for an array with shape (1, 1, 56, 376, 376) and data type float32\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\batchgenerators\\dataloading\\nondet_multi_threaded_augmenter.py\", line 53, in producer\n",
      "    item = next(data_loader)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\batchgenerators\\dataloading\\data_loader.py\", line 126, in __next__\n",
      "    return self.generate_train_batch()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\nnunetv2\\training\\dataloading\\data_loader.py\", line 170, in generate_train_batch\n",
      "    data_all = np.zeros(self.data_shape, dtype=np.float32)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "numpy._core._exceptions._ArrayMemoryError: Unable to allocate 30.2 MiB for an array with shape (1, 1, 56, 376, 376) and data type float32\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\batchgenerators\\dataloading\\nondet_multi_threaded_augmenter.py\", line 53, in producer\n",
      "    item = next(data_loader)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\batchgenerators\\dataloading\\data_loader.py\", line 126, in __next__\n",
      "    return self.generate_train_batch()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\nnunetv2\\training\\dataloading\\data_loader.py\", line 170, in generate_train_batch\n",
      "    data_all = np.zeros(self.data_shape, dtype=np.float32)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\batchgenerators\\dataloading\\nondet_multi_threaded_augmenter.py\", line 53, in producer\n",
      "    item = next(data_loader)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\batchgenerators\\dataloading\\data_loader.py\", line 126, in __next__\n",
      "    return self.generate_train_batch()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\nnunetv2\\training\\dataloading\\data_loader.py\", line 170, in generate_train_batch\n",
      "    data_all = np.zeros(self.data_shape, dtype=np.float32)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "numpy._core._exceptions._ArrayMemoryError: Unable to allocate 30.2 MiB for an array with shape (1, 1, 56, 376, 376) and data type float32\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\batchgenerators\\dataloading\\nondet_multi_threaded_augmenter.py\", line 53, in producer\n",
      "    item = next(data_loader)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\batchgenerators\\dataloading\\data_loader.py\", line 126, in __next__\n",
      "    return self.generate_train_batch()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\nnunetv2\\training\\dataloading\\data_loader.py\", line 170, in generate_train_batch\n",
      "    data_all = np.zeros(self.data_shape, dtype=np.float32)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "numpy._core._exceptions._ArrayMemoryError: Unable to allocate 30.2 MiB for an array with shape (1, 1, 56, 376, 376) and data type float32\n",
      "numpy._core._exceptions._ArrayMemoryError: Unable to allocate 30.2 MiB for an array with shape (1, 1, 56, 376, 376) and data type float32\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\multiprocessing\\queues.py\", line 264, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\multiprocessing\\reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\multiprocessing\\reductions.py\", line 607, in reduce_storage\n",
      "    metadata = storage._share_filename_cpu_()\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\storage.py\", line 447, in wrapper\n",
      "    return fn(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\storage.py\", line 526, in _share_filename_cpu_\n",
      "    return super()._share_filename_cpu_(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Couldn't open shared file mapping: <torch_26100_3265640783_4711>, error code: <1455>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\multiprocessing\\queues.py\", line 264, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\multiprocessing\\reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\multiprocessing\\reductions.py\", line 607, in reduce_storage\n",
      "    metadata = storage._share_filename_cpu_()\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\storage.py\", line 447, in wrapper\n",
      "    return fn(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\storage.py\", line 526, in _share_filename_cpu_\n",
      "    return super()._share_filename_cpu_(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Couldn't open shared file mapping: <torch_21604_1128297587_4963>, error code: <1455>\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\multiprocessing\\queues.py\", line 264, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\multiprocessing\\reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\multiprocessing\\reductions.py\", line 607, in reduce_storage\n",
      "    metadata = storage._share_filename_cpu_()\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\storage.py\", line 447, in wrapper\n",
      "    return fn(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\storage.py\", line 526, in _share_filename_cpu_\n",
      "    return super()._share_filename_cpu_(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Couldn't open shared file mapping: <torch_21896_503204941_4670>, error code: <1455>\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\multiprocessing\\queues.py\", line 264, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\multiprocessing\\reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\multiprocessing\\reductions.py\", line 607, in reduce_storage\n",
      "    metadata = storage._share_filename_cpu_()\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\storage.py\", line 447, in wrapper\n",
      "    return fn(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\storage.py\", line 526, in _share_filename_cpu_\n",
      "    return super()._share_filename_cpu_(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Couldn't open shared file mapping: <torch_11812_1277556452_5082>, error code: <1455>\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\multiprocessing\\queues.py\", line 264, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\multiprocessing\\reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\multiprocessing\\reductions.py\", line 607, in reduce_storage\n",
      "    metadata = storage._share_filename_cpu_()\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\storage.py\", line 447, in wrapper\n",
      "    return fn(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\storage.py\", line 526, in _share_filename_cpu_\n",
      "    return super()._share_filename_cpu_(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Couldn't open shared file mapping: <torch_26400_3759565864_4879>, error code: <1455>\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\multiprocessing\\queues.py\", line 264, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\multiprocessing\\reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\multiprocessing\\reductions.py\", line 607, in reduce_storage\n",
      "    metadata = storage._share_filename_cpu_()\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\storage.py\", line 447, in wrapper\n",
      "    return fn(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\storage.py\", line 526, in _share_filename_cpu_\n",
      "    return super()._share_filename_cpu_(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Couldn't open shared file mapping: <torch_28796_2960475631_5089>, error code: <1455>\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\multiprocessing\\queues.py\", line 264, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\multiprocessing\\reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\multiprocessing\\reductions.py\", line 607, in reduce_storage\n",
      "    metadata = storage._share_filename_cpu_()\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\storage.py\", line 447, in wrapper\n",
      "    return fn(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\storage.py\", line 526, in _share_filename_cpu_\n",
      "    return super()._share_filename_cpu_(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Couldn't open shared file mapping: <torch_12788_2471960399_4823>, error code: <1455>\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\multiprocessing\\queues.py\", line 264, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\multiprocessing\\reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\multiprocessing\\reductions.py\", line 607, in reduce_storage\n",
      "    metadata = storage._share_filename_cpu_()\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\storage.py\", line 447, in wrapper\n",
      "    return fn(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\storage.py\", line 526, in _share_filename_cpu_\n",
      "    return super()._share_filename_cpu_(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Couldn't open shared file mapping: <torch_15940_3585350670_5245>, error code: <1455>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\batchgenerators\\dataloading\\nondet_multi_threaded_augmenter.py\", line 53, in producer\n",
      "    item = next(data_loader)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\batchgenerators\\dataloading\\data_loader.py\", line 126, in __next__\n",
      "    return self.generate_train_batch()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\nnunetv2\\training\\dataloading\\data_loader.py\", line 188, in generate_train_batch\n",
      "    data_all[j] = crop_and_pad_nd(data, bbox, 0)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\acvl_utils\\cropping_and_padding\\bounding_boxes.py\", line 280, in crop_and_pad_nd\n",
      "    cropped = image[tuple(slices)]\n",
      "              ~~~~~^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\blosc2\\ndarray.py\", line 1524, in __getitem__\n",
      "    arr = np.empty(shape, dtype=self.dtype)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "numpy._core._exceptions._ArrayMemoryError: Unable to allocate 29.5 MiB for an array with shape (1, 56, 376, 367) and data type float32\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\multiprocessing\\queues.py\", line 264, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\multiprocessing\\reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\multiprocessing\\reductions.py\", line 607, in reduce_storage\n",
      "    metadata = storage._share_filename_cpu_()\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\storage.py\", line 447, in wrapper\n",
      "    return fn(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\storage.py\", line 526, in _share_filename_cpu_\n",
      "    return super()._share_filename_cpu_(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Couldn't open shared file mapping: <torch_26300_2839226711_5061>, error code: <1455>\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Scripts\\nnUNetv2_train.exe\\__main__.py\", line 7, in <module>\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\nnunetv2\\run\\run_training.py\", line 267, in run_training_entry\n",
      "    run_training(args.dataset_name_or_id, args.configuration, args.fold, args.tr, args.p, args.pretrained_weights,\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\nnunetv2\\run\\run_training.py\", line 207, in run_training\n",
      "    nnunet_trainer.run_training()\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\nnunetv2\\training\\nnUNetTrainer\\nnUNetTrainer.py\", line 1371, in run_training\n",
      "    train_outputs.append(self.train_step(next(self.dataloader_train)))\n",
      "                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\batchgenerators\\dataloading\\nondet_multi_threaded_augmenter.py\", line 196, in __next__\n",
      "    item = self.__get_next_item()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\batchgenerators\\dataloading\\nondet_multi_threaded_augmenter.py\", line 181, in __get_next_item\n",
      "    raise RuntimeError(\"One or more background workers are no longer alive. Exiting. Please check the \"\n",
      "RuntimeError: One or more background workers are no longer alive. Exiting. Please check the print statements above for the actual error message\n",
      "Exception in thread Thread-2 (results_loop):\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\threading.py\", line 1075, in _bootstrap_inner\n",
      "Exception ignored in: <function NonDetMultiThreadedAugmenter.__del__ at 0x000002B0DDEF7BA0>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\batchgenerators\\dataloading\\nondet_multi_threaded_augmenter.py\", line 259, in __del__\n",
      "    self._finish()\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\batchgenerators\\dataloading\\nondet_multi_threaded_augmenter.py\", line 244, in _finish\n",
      "    self.abort_event.set()\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\multiprocessing\\synchronize.py\", line 345, in set\n",
      "    self._cond.notify_all()\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\multiprocessing\\synchronize.py\", line 304, in notify_all\n",
      "    self.notify(n=sys.maxsize)\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\multiprocessing\\synchronize.py\", line 279, in notify\n",
      "    assert not self._wait_semaphore.acquire(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "OSError: [WinError 6] 控制代碼無效。\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"NNUNET_MAX_EPOCHS\"] = \"10\"\n",
    "\n",
    "!nnUNetv2_train 1 3d_fullres 1 \\\n",
    "                -p nnUNetResEncUNetLPlans \\\n",
    "                --npz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O_0QGCZ5GS-2"
   },
   "source": [
    "## find best configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 2906,
     "status": "ok",
     "timestamp": 1742283271993,
     "user": {
      "displayName": "LAB AI",
      "userId": "05090763676444143877"
     },
     "user_tz": -480
    },
    "id": "EhfKAsqkGWVO",
    "outputId": "b0d3b71b-1e1d-4aee-f884-13dc32f0f190"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: nnUNetv2_find_best_configuration [-h] [-p P [P ...]] [-c C [C ...]]\n",
      "                                        [-tr TR [TR ...]] [-np NP]\n",
      "                                        [-f F [F ...]] [--disable_ensembling]\n",
      "                                        [--no_overwrite]\n",
      "                                        dataset_name_or_id\n",
      "\n",
      "positional arguments:\n",
      "  dataset_name_or_id    Dataset Name or id\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  -p P [P ...]          List of plan identifiers. Default: nnUNetPlans\n",
      "  -c C [C ...]          List of configurations. Default: ['2d', '3d_fullres',\n",
      "                        '3d_lowres', '3d_cascade_fullres']\n",
      "  -tr TR [TR ...]       List of trainers. Default: nnUNetTrainer\n",
      "  -np NP                Number of processes to use for ensembling,\n",
      "                        postprocessing etc\n",
      "  -f F [F ...]          Folds to use. Default: 0 1 2 3 4\n",
      "  --disable_ensembling  Set this flag to disable ensembling\n",
      "  --no_overwrite        If set we will not overwrite already ensembled files\n",
      "                        etc. May speed up concecutive runs of this command\n",
      "                        (why would you want to do that?) at the risk of not\n",
      "                        updating outdated results.\n"
     ]
    }
   ],
   "source": [
    "# !nnUNetv2_find_best_configuration -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 362529,
     "status": "ok",
     "timestamp": 1742287016613,
     "user": {
      "displayName": "LAB AI",
      "userId": "05090763676444143877"
     },
     "user_tz": -480
    },
    "id": "icZoyCYeHiV1",
    "outputId": "5eec07e7-1499-4a6a-cd03-53e7567bd071"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Scripts\\nnUNetv2_find_best_configuration.exe\\__main__.py\", line 7, in <module>\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\nnunetv2\\evaluation\\find_best_configuration.py\", line 296, in find_best_configuration_entry_point\n",
      "    find_best_configuration(dataset_name, model_dict, allow_ensembling=not args.disable_ensembling,\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\nnunetv2\\evaluation\\find_best_configuration.py\", line 101, in find_best_configuration\n",
      "    accumulate_cv_results(output_folder, merged_output_folder, folds, num_processes, overwrite)\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\nnunetv2\\evaluation\\accumulate_cv_results.py\", line 36, in accumulate_cv_results\n",
      "    raise RuntimeError(f\"fold {f} of model {trained_model_folder} is missing. Please train it!\")\n",
      "RuntimeError: fold 1 of model C:\\Users\\CUTY\\Desktop\\AOR\\nnU_Base\\nnUNet_trained_models\\Dataset001_MYTASK\\nnUNetTrainer__nnUNetResEncUNetLPlans__3d_fullres is missing. Please train it!\n"
     ]
    }
   ],
   "source": [
    "# !nnUNetv2_find_best_configuration 1 \\\n",
    "#     -p nnUNetResEncUNetLPlans \\\n",
    "#     -c 3d_fullres \\\n",
    "#     -f 1\n",
    "#     #-f 0 1 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ThQEgT5mt5hJ"
   },
   "source": [
    "## predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n_tYVmGWbkFH"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'cp' ���O�����Υ~���R�O�B�i���檺�{���Χ妸�ɡC\n"
     ]
    }
   ],
   "source": [
    "# !cp -r '/content/drive/MyDrive/poster/NNUNET/predict/input_partial' '/content'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#######################################################################\n",
      "Please cite the following paper when using nnU-Net:\n",
      "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
      "#######################################################################\n",
      "\n",
      "There are 20 cases in the source folder\n",
      "I am process 0 out of 1 (max process ID is 0, we start counting with 0!)\n",
      "There are 20 cases that I would like to predict\n",
      "\n",
      "Predicting AA:\n",
      "perform_everything_on_device: True\n",
      "sending off prediction to background worker for resampling and export\n",
      "done with AA\n",
      "\n",
      "Predicting AB:\n",
      "perform_everything_on_device: True\n",
      "sending off prediction to background worker for resampling and export\n",
      "done with AB\n",
      "\n",
      "Predicting AC:\n",
      "perform_everything_on_device: True\n",
      "sending off prediction to background worker for resampling and export\n",
      "done with AC\n",
      "\n",
      "Predicting AD:\n",
      "perform_everything_on_device: True\n",
      "sending off prediction to background worker for resampling and export\n",
      "done with AD\n",
      "\n",
      "Predicting AE:\n",
      "perform_everything_on_device: True\n",
      "sending off prediction to background worker for resampling and export\n",
      "done with AE\n",
      "\n",
      "Predicting AF:\n",
      "perform_everything_on_device: True\n",
      "sending off prediction to background worker for resampling and export\n",
      "done with AF\n",
      "\n",
      "Predicting AG:\n",
      "perform_everything_on_device: True\n",
      "sending off prediction to background worker for resampling and export\n",
      "done with AG\n",
      "\n",
      "Predicting AH:\n",
      "perform_everything_on_device: True\n",
      "sending off prediction to background worker for resampling and export\n",
      "done with AH\n",
      "\n",
      "Predicting AI:\n",
      "perform_everything_on_device: True\n",
      "sending off prediction to background worker for resampling and export\n",
      "done with AI\n",
      "\n",
      "Predicting AJ:\n",
      "perform_everything_on_device: True\n",
      "sending off prediction to background worker for resampling and export\n",
      "done with AJ\n",
      "\n",
      "Predicting AK:\n",
      "perform_everything_on_device: True\n",
      "sending off prediction to background worker for resampling and export\n",
      "done with AK\n",
      "\n",
      "Predicting AL:\n",
      "perform_everything_on_device: True\n",
      "sending off prediction to background worker for resampling and export\n",
      "done with AL\n",
      "\n",
      "Predicting AM:\n",
      "perform_everything_on_device: True\n",
      "sending off prediction to background worker for resampling and export\n",
      "done with AM\n",
      "\n",
      "Predicting AN:\n",
      "perform_everything_on_device: True\n",
      "sending off prediction to background worker for resampling and export\n",
      "done with AN\n",
      "\n",
      "Predicting AO:\n",
      "perform_everything_on_device: True\n",
      "sending off prediction to background worker for resampling and export\n",
      "done with AO\n",
      "\n",
      "Predicting AP:\n",
      "perform_everything_on_device: True\n",
      "sending off prediction to background worker for resampling and export\n",
      "done with AP\n",
      "\n",
      "Predicting AQ:\n",
      "perform_everything_on_device: True\n",
      "sending off prediction to background worker for resampling and export\n",
      "done with AQ\n",
      "\n",
      "Predicting AR:\n",
      "perform_everything_on_device: True\n",
      "sending off prediction to background worker for resampling and export\n",
      "done with AR\n",
      "\n",
      "Predicting AS:\n",
      "perform_everything_on_device: True\n",
      "sending off prediction to background worker for resampling and export\n",
      "done with AS\n",
      "\n",
      "Predicting AT:\n",
      "perform_everything_on_device: True\n",
      "sending off prediction to background worker for resampling and export\n",
      "done with AT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/18 [00:00<?, ?it/s]\n",
      "  6%|▌         | 1/18 [00:05<01:25,  5.00s/it]\n",
      " 33%|███▎      | 6/18 [00:05<00:07,  1.50it/s]\n",
      " 44%|████▍     | 8/18 [00:06<00:05,  1.73it/s]\n",
      " 50%|█████     | 9/18 [00:06<00:04,  1.85it/s]\n",
      " 56%|█████▌    | 10/18 [00:06<00:04,  1.96it/s]\n",
      " 61%|██████    | 11/18 [00:07<00:03,  2.06it/s]\n",
      " 67%|██████▋   | 12/18 [00:07<00:02,  2.16it/s]\n",
      " 72%|███████▏  | 13/18 [00:08<00:02,  2.25it/s]\n",
      " 78%|███████▊  | 14/18 [00:08<00:01,  2.32it/s]\n",
      " 83%|████████▎ | 15/18 [00:08<00:01,  2.40it/s]\n",
      " 89%|████████▉ | 16/18 [00:09<00:00,  2.41it/s]\n",
      " 94%|█████████▍| 17/18 [00:09<00:00,  2.44it/s]\n",
      "100%|██████████| 18/18 [00:10<00:00,  2.46it/s]\n",
      "100%|██████████| 18/18 [00:10<00:00,  1.79it/s]\n",
      "\n",
      "  0%|          | 0/27 [00:00<?, ?it/s]\n",
      " 19%|█▊        | 5/27 [00:00<00:01, 14.84it/s]\n",
      " 26%|██▌       | 7/27 [00:01<00:03,  5.37it/s]\n",
      " 30%|██▉       | 8/27 [00:01<00:04,  4.35it/s]\n",
      " 33%|███▎      | 9/27 [00:01<00:04,  3.74it/s]\n",
      " 37%|███▋      | 10/27 [00:02<00:05,  3.35it/s]\n",
      " 41%|████      | 11/27 [00:02<00:05,  3.09it/s]\n",
      " 44%|████▍     | 12/27 [00:03<00:05,  2.92it/s]\n",
      " 48%|████▊     | 13/27 [00:03<00:05,  2.77it/s]\n",
      " 52%|█████▏    | 14/27 [00:03<00:04,  2.71it/s]\n",
      " 56%|█████▌    | 15/27 [00:04<00:04,  2.64it/s]\n",
      " 59%|█████▉    | 16/27 [00:04<00:04,  2.61it/s]\n",
      " 63%|██████▎   | 17/27 [00:05<00:03,  2.56it/s]\n",
      " 67%|██████▋   | 18/27 [00:05<00:03,  2.54it/s]\n",
      " 70%|███████   | 19/27 [00:05<00:03,  2.55it/s]\n",
      " 74%|███████▍  | 20/27 [00:06<00:02,  2.54it/s]\n",
      " 78%|███████▊  | 21/27 [00:06<00:02,  2.53it/s]\n",
      " 81%|████████▏ | 22/27 [00:07<00:01,  2.52it/s]\n",
      " 85%|████████▌ | 23/27 [00:07<00:01,  2.53it/s]\n",
      " 89%|████████▉ | 24/27 [00:07<00:01,  2.51it/s]\n",
      " 93%|█████████▎| 25/27 [00:08<00:00,  2.53it/s]\n",
      " 96%|█████████▋| 26/27 [00:08<00:00,  2.51it/s]\n",
      "100%|██████████| 27/27 [00:09<00:00,  2.52it/s]\n",
      "100%|██████████| 27/27 [00:09<00:00,  2.98it/s]\n",
      "\n",
      "  0%|          | 0/36 [00:00<?, ?it/s]\n",
      " 14%|█▍        | 5/36 [00:00<00:02, 15.34it/s]\n",
      " 19%|█▉        | 7/36 [00:01<00:05,  5.51it/s]\n",
      " 22%|██▏       | 8/36 [00:01<00:06,  4.39it/s]\n",
      " 25%|██▌       | 9/36 [00:01<00:07,  3.78it/s]\n",
      " 28%|██▊       | 10/36 [00:02<00:07,  3.42it/s]\n",
      " 31%|███       | 11/36 [00:02<00:07,  3.18it/s]\n",
      " 33%|███▎      | 12/36 [00:03<00:08,  2.98it/s]\n",
      " 36%|███▌      | 13/36 [00:03<00:08,  2.85it/s]\n",
      " 39%|███▉      | 14/36 [00:03<00:07,  2.80it/s]\n",
      " 42%|████▏     | 15/36 [00:04<00:07,  2.76it/s]\n",
      " 44%|████▍     | 16/36 [00:04<00:07,  2.70it/s]\n",
      " 47%|████▋     | 17/36 [00:04<00:07,  2.67it/s]\n",
      " 50%|█████     | 18/36 [00:05<00:06,  2.66it/s]\n",
      " 53%|█████▎    | 19/36 [00:05<00:06,  2.65it/s]\n",
      " 56%|█████▌    | 20/36 [00:06<00:06,  2.63it/s]\n",
      " 58%|█████▊    | 21/36 [00:06<00:05,  2.64it/s]\n",
      " 61%|██████    | 22/36 [00:06<00:05,  2.65it/s]\n",
      " 64%|██████▍   | 23/36 [00:07<00:04,  2.62it/s]\n",
      " 67%|██████▋   | 24/36 [00:07<00:04,  2.64it/s]\n",
      " 69%|██████▉   | 25/36 [00:07<00:04,  2.63it/s]\n",
      " 72%|███████▏  | 26/36 [00:08<00:03,  2.64it/s]\n",
      " 75%|███████▌  | 27/36 [00:08<00:03,  2.61it/s]\n",
      " 78%|███████▊  | 28/36 [00:09<00:03,  2.63it/s]\n",
      " 81%|████████  | 29/36 [00:09<00:02,  2.63it/s]\n",
      " 83%|████████▎ | 30/36 [00:09<00:02,  2.61it/s]\n",
      " 86%|████████▌ | 31/36 [00:10<00:01,  2.63it/s]\n",
      " 89%|████████▉ | 32/36 [00:10<00:01,  2.61it/s]\n",
      " 92%|█████████▏| 33/36 [00:11<00:01,  2.63it/s]\n",
      " 94%|█████████▍| 34/36 [00:11<00:00,  2.62it/s]\n",
      " 97%|█████████▋| 35/36 [00:11<00:00,  2.63it/s]\n",
      "100%|██████████| 36/36 [00:12<00:00,  2.63it/s]\n",
      "100%|██████████| 36/36 [00:12<00:00,  2.95it/s]\n",
      "\n",
      "  0%|          | 0/36 [00:00<?, ?it/s]\n",
      " 14%|█▍        | 5/36 [00:00<00:02, 14.97it/s]\n",
      " 19%|█▉        | 7/36 [00:01<00:05,  5.53it/s]\n",
      " 22%|██▏       | 8/36 [00:01<00:06,  4.50it/s]\n",
      " 25%|██▌       | 9/36 [00:01<00:07,  3.85it/s]\n",
      " 28%|██▊       | 10/36 [00:02<00:07,  3.46it/s]\n",
      " 31%|███       | 11/36 [00:02<00:07,  3.16it/s]\n",
      " 33%|███▎      | 12/36 [00:03<00:07,  3.02it/s]\n",
      " 36%|███▌      | 13/36 [00:03<00:07,  2.90it/s]\n",
      " 39%|███▉      | 14/36 [00:03<00:07,  2.82it/s]\n",
      " 42%|████▏     | 15/36 [00:04<00:07,  2.73it/s]\n",
      " 44%|████▍     | 16/36 [00:04<00:07,  2.71it/s]\n",
      " 47%|████▋     | 17/36 [00:04<00:07,  2.69it/s]\n",
      " 50%|█████     | 18/36 [00:05<00:06,  2.68it/s]\n",
      " 53%|█████▎    | 19/36 [00:05<00:06,  2.64it/s]\n",
      " 56%|█████▌    | 20/36 [00:06<00:06,  2.64it/s]\n",
      " 58%|█████▊    | 21/36 [00:06<00:05,  2.64it/s]\n",
      " 61%|██████    | 22/36 [00:06<00:05,  2.63it/s]\n",
      " 64%|██████▍   | 23/36 [00:07<00:04,  2.63it/s]\n",
      " 67%|██████▋   | 24/36 [00:07<00:04,  2.65it/s]\n",
      " 69%|██████▉   | 25/36 [00:07<00:04,  2.61it/s]\n",
      " 72%|███████▏  | 26/36 [00:08<00:03,  2.59it/s]\n",
      " 75%|███████▌  | 27/36 [00:08<00:03,  2.61it/s]\n",
      " 78%|███████▊  | 28/36 [00:09<00:03,  2.58it/s]\n",
      " 81%|████████  | 29/36 [00:09<00:02,  2.60it/s]\n",
      " 83%|████████▎ | 30/36 [00:09<00:02,  2.58it/s]\n",
      " 86%|████████▌ | 31/36 [00:10<00:01,  2.60it/s]\n",
      " 89%|████████▉ | 32/36 [00:10<00:01,  2.59it/s]\n",
      " 92%|█████████▏| 33/36 [00:11<00:01,  2.58it/s]\n",
      " 94%|█████████▍| 34/36 [00:11<00:00,  2.57it/s]\n",
      " 97%|█████████▋| 35/36 [00:11<00:00,  2.60it/s]\n",
      "100%|██████████| 36/36 [00:12<00:00,  2.61it/s]\n",
      "100%|██████████| 36/36 [00:12<00:00,  2.95it/s]\n",
      "\n",
      "  0%|          | 0/27 [00:00<?, ?it/s]\n",
      " 19%|█▊        | 5/27 [00:00<00:01, 15.34it/s]\n",
      " 26%|██▌       | 7/27 [00:01<00:03,  5.52it/s]\n",
      " 30%|██▉       | 8/27 [00:01<00:04,  4.44it/s]\n",
      " 33%|███▎      | 9/27 [00:01<00:04,  3.79it/s]\n",
      " 37%|███▋      | 10/27 [00:02<00:04,  3.42it/s]\n",
      " 41%|████      | 11/27 [00:02<00:05,  3.15it/s]\n",
      " 44%|████▍     | 12/27 [00:03<00:05,  2.98it/s]\n",
      " 48%|████▊     | 13/27 [00:03<00:04,  2.87it/s]\n",
      " 52%|█████▏    | 14/27 [00:03<00:04,  2.81it/s]\n",
      " 56%|█████▌    | 15/27 [00:04<00:04,  2.75it/s]\n",
      " 59%|█████▉    | 16/27 [00:04<00:04,  2.70it/s]\n",
      " 63%|██████▎   | 17/27 [00:04<00:03,  2.69it/s]\n",
      " 67%|██████▋   | 18/27 [00:05<00:03,  2.67it/s]\n",
      " 70%|███████   | 19/27 [00:05<00:03,  2.64it/s]\n",
      " 74%|███████▍  | 20/27 [00:06<00:02,  2.65it/s]\n",
      " 78%|███████▊  | 21/27 [00:06<00:02,  2.63it/s]\n",
      " 81%|████████▏ | 22/27 [00:06<00:01,  2.60it/s]\n",
      " 85%|████████▌ | 23/27 [00:07<00:01,  2.62it/s]\n",
      " 89%|████████▉ | 24/27 [00:07<00:01,  2.60it/s]\n",
      " 93%|█████████▎| 25/27 [00:08<00:00,  2.63it/s]\n",
      " 96%|█████████▋| 26/27 [00:08<00:00,  2.60it/s]\n",
      "100%|██████████| 27/27 [00:08<00:00,  2.58it/s]\n",
      "100%|██████████| 27/27 [00:08<00:00,  3.07it/s]\n",
      "\n",
      "  0%|          | 0/36 [00:00<?, ?it/s]\n",
      " 14%|█▍        | 5/36 [00:00<00:02, 15.34it/s]\n",
      " 19%|█▉        | 7/36 [00:01<00:05,  5.53it/s]\n",
      " 22%|██▏       | 8/36 [00:01<00:06,  4.51it/s]\n",
      " 25%|██▌       | 9/36 [00:01<00:06,  3.89it/s]\n",
      " 28%|██▊       | 10/36 [00:02<00:07,  3.47it/s]\n",
      " 31%|███       | 11/36 [00:02<00:07,  3.18it/s]\n",
      " 33%|███▎      | 12/36 [00:03<00:07,  3.00it/s]\n",
      " 36%|███▌      | 13/36 [00:03<00:07,  2.89it/s]\n",
      " 39%|███▉      | 14/36 [00:03<00:07,  2.81it/s]\n",
      " 42%|████▏     | 15/36 [00:04<00:07,  2.70it/s]\n",
      " 44%|████▍     | 16/36 [00:04<00:07,  2.67it/s]\n",
      " 47%|████▋     | 17/36 [00:04<00:07,  2.65it/s]\n",
      " 50%|█████     | 18/36 [00:05<00:06,  2.62it/s]\n",
      " 53%|█████▎    | 19/36 [00:05<00:06,  2.61it/s]\n",
      " 56%|█████▌    | 20/36 [00:06<00:06,  2.60it/s]\n",
      " 58%|█████▊    | 21/36 [00:06<00:05,  2.59it/s]\n",
      " 61%|██████    | 22/36 [00:06<00:05,  2.61it/s]\n",
      " 64%|██████▍   | 23/36 [00:07<00:05,  2.56it/s]\n",
      " 67%|██████▋   | 24/36 [00:07<00:04,  2.57it/s]\n",
      " 69%|██████▉   | 25/36 [00:08<00:04,  2.55it/s]\n",
      " 72%|███████▏  | 26/36 [00:08<00:03,  2.55it/s]\n",
      " 75%|███████▌  | 27/36 [00:08<00:03,  2.59it/s]\n",
      " 78%|███████▊  | 28/36 [00:09<00:03,  2.58it/s]\n",
      " 81%|████████  | 29/36 [00:09<00:02,  2.58it/s]\n",
      " 83%|████████▎ | 30/36 [00:10<00:02,  2.56it/s]\n",
      " 86%|████████▌ | 31/36 [00:10<00:01,  2.57it/s]\n",
      " 89%|████████▉ | 32/36 [00:10<00:01,  2.56it/s]\n",
      " 92%|█████████▏| 33/36 [00:11<00:01,  2.53it/s]\n",
      " 94%|█████████▍| 34/36 [00:11<00:00,  2.53it/s]\n",
      " 97%|█████████▋| 35/36 [00:11<00:00,  2.57it/s]\n",
      "100%|██████████| 36/36 [00:12<00:00,  2.59it/s]\n",
      "100%|██████████| 36/36 [00:12<00:00,  2.92it/s]\n",
      "\n",
      "  0%|          | 0/36 [00:00<?, ?it/s]\n",
      " 14%|█▍        | 5/36 [00:00<00:02, 15.43it/s]\n",
      " 19%|█▉        | 7/36 [00:01<00:05,  5.57it/s]\n",
      " 22%|██▏       | 8/36 [00:01<00:06,  4.48it/s]\n",
      " 25%|██▌       | 9/36 [00:01<00:06,  3.86it/s]\n",
      " 28%|██▊       | 10/36 [00:02<00:07,  3.43it/s]\n",
      " 31%|███       | 11/36 [00:02<00:07,  3.18it/s]\n",
      " 33%|███▎      | 12/36 [00:03<00:07,  3.02it/s]\n",
      " 36%|███▌      | 13/36 [00:03<00:07,  2.90it/s]\n",
      " 39%|███▉      | 14/36 [00:03<00:07,  2.80it/s]\n",
      " 42%|████▏     | 15/36 [00:04<00:07,  2.76it/s]\n",
      " 44%|████▍     | 16/36 [00:04<00:07,  2.70it/s]\n",
      " 47%|████▋     | 17/36 [00:04<00:07,  2.68it/s]\n",
      " 50%|█████     | 18/36 [00:05<00:06,  2.65it/s]\n",
      " 53%|█████▎    | 19/36 [00:05<00:06,  2.66it/s]\n",
      " 56%|█████▌    | 20/36 [00:06<00:06,  2.63it/s]\n",
      " 58%|█████▊    | 21/36 [00:06<00:05,  2.62it/s]\n",
      " 61%|██████    | 22/36 [00:06<00:05,  2.63it/s]\n",
      " 64%|██████▍   | 23/36 [00:07<00:04,  2.61it/s]\n",
      " 67%|██████▋   | 24/36 [00:07<00:04,  2.64it/s]\n",
      " 69%|██████▉   | 25/36 [00:07<00:04,  2.61it/s]\n",
      " 72%|███████▏  | 26/36 [00:08<00:03,  2.63it/s]\n",
      " 75%|███████▌  | 27/36 [00:08<00:03,  2.60it/s]\n",
      " 78%|███████▊  | 28/36 [00:09<00:03,  2.62it/s]\n",
      " 81%|████████  | 29/36 [00:09<00:02,  2.61it/s]\n",
      " 83%|████████▎ | 30/36 [00:09<00:02,  2.63it/s]\n",
      " 86%|████████▌ | 31/36 [00:10<00:01,  2.61it/s]\n",
      " 89%|████████▉ | 32/36 [00:10<00:01,  2.60it/s]\n",
      " 92%|█████████▏| 33/36 [00:11<00:01,  2.62it/s]\n",
      " 94%|█████████▍| 34/36 [00:11<00:00,  2.62it/s]\n",
      " 97%|█████████▋| 35/36 [00:11<00:00,  2.61it/s]\n",
      "100%|██████████| 36/36 [00:12<00:00,  2.61it/s]\n",
      "100%|██████████| 36/36 [00:12<00:00,  2.95it/s]\n",
      "\n",
      "  0%|          | 0/18 [00:00<?, ?it/s]\n",
      " 28%|██▊       | 5/18 [00:00<00:00, 15.20it/s]\n",
      " 39%|███▉      | 7/18 [00:01<00:01,  5.60it/s]\n",
      " 44%|████▍     | 8/18 [00:01<00:02,  4.53it/s]\n",
      " 50%|█████     | 9/18 [00:01<00:02,  3.85it/s]\n",
      " 56%|█████▌    | 10/18 [00:02<00:02,  3.46it/s]\n",
      " 61%|██████    | 11/18 [00:02<00:02,  3.18it/s]\n",
      " 67%|██████▋   | 12/18 [00:02<00:01,  3.02it/s]\n",
      " 72%|███████▏  | 13/18 [00:03<00:01,  2.88it/s]\n",
      " 78%|███████▊  | 14/18 [00:03<00:01,  2.79it/s]\n",
      " 83%|████████▎ | 15/18 [00:04<00:01,  2.74it/s]\n",
      " 89%|████████▉ | 16/18 [00:04<00:00,  2.69it/s]\n",
      " 94%|█████████▍| 17/18 [00:04<00:00,  2.68it/s]\n",
      "100%|██████████| 18/18 [00:05<00:00,  2.65it/s]\n",
      "100%|██████████| 18/18 [00:05<00:00,  3.39it/s]\n",
      "\n",
      "  0%|          | 0/36 [00:00<?, ?it/s]\n",
      " 14%|█▍        | 5/36 [00:00<00:01, 15.53it/s]\n",
      " 19%|█▉        | 7/36 [00:01<00:05,  5.55it/s]\n",
      " 22%|██▏       | 8/36 [00:01<00:06,  4.49it/s]\n",
      " 25%|██▌       | 9/36 [00:01<00:06,  3.88it/s]\n",
      " 28%|██▊       | 10/36 [00:02<00:07,  3.43it/s]\n",
      " 31%|███       | 11/36 [00:02<00:07,  3.18it/s]\n",
      " 33%|███▎      | 12/36 [00:03<00:07,  3.02it/s]\n",
      " 36%|███▌      | 13/36 [00:03<00:08,  2.87it/s]\n",
      " 39%|███▉      | 14/36 [00:03<00:07,  2.80it/s]\n",
      " 42%|████▏     | 15/36 [00:04<00:07,  2.73it/s]\n",
      " 44%|████▍     | 16/36 [00:04<00:07,  2.69it/s]\n",
      " 47%|████▋     | 17/36 [00:04<00:07,  2.65it/s]\n",
      " 50%|█████     | 18/36 [00:05<00:06,  2.62it/s]\n",
      " 53%|█████▎    | 19/36 [00:05<00:06,  2.58it/s]\n",
      " 56%|█████▌    | 20/36 [00:06<00:06,  2.59it/s]\n",
      " 58%|█████▊    | 21/36 [00:06<00:05,  2.57it/s]\n",
      " 61%|██████    | 22/36 [00:06<00:05,  2.57it/s]\n",
      " 64%|██████▍   | 23/36 [00:07<00:05,  2.55it/s]\n",
      " 67%|██████▋   | 24/36 [00:07<00:04,  2.53it/s]\n",
      " 69%|██████▉   | 25/36 [00:08<00:04,  2.54it/s]\n",
      " 72%|███████▏  | 26/36 [00:08<00:03,  2.55it/s]\n",
      " 75%|███████▌  | 27/36 [00:08<00:03,  2.58it/s]\n",
      " 78%|███████▊  | 28/36 [00:09<00:03,  2.56it/s]\n",
      " 81%|████████  | 29/36 [00:09<00:02,  2.59it/s]\n",
      " 83%|████████▎ | 30/36 [00:10<00:02,  2.58it/s]\n",
      " 86%|████████▌ | 31/36 [00:10<00:01,  2.60it/s]\n",
      " 89%|████████▉ | 32/36 [00:10<00:01,  2.57it/s]\n",
      " 92%|█████████▏| 33/36 [00:11<00:01,  2.58it/s]\n",
      " 94%|█████████▍| 34/36 [00:11<00:00,  2.56it/s]\n",
      " 97%|█████████▋| 35/36 [00:11<00:00,  2.56it/s]\n",
      "100%|██████████| 36/36 [00:12<00:00,  2.56it/s]\n",
      "100%|██████████| 36/36 [00:12<00:00,  2.91it/s]\n",
      "\n",
      "  0%|          | 0/36 [00:00<?, ?it/s]\n",
      " 14%|█▍        | 5/36 [00:00<00:02, 15.24it/s]\n",
      " 19%|█▉        | 7/36 [00:01<00:05,  5.44it/s]\n",
      " 22%|██▏       | 8/36 [00:01<00:06,  4.36it/s]\n",
      " 25%|██▌       | 9/36 [00:01<00:07,  3.71it/s]\n",
      " 28%|██▊       | 10/36 [00:02<00:07,  3.35it/s]\n",
      " 31%|███       | 11/36 [00:02<00:08,  3.10it/s]\n",
      " 33%|███▎      | 12/36 [00:03<00:08,  2.94it/s]\n",
      " 36%|███▌      | 13/36 [00:03<00:08,  2.82it/s]\n",
      " 39%|███▉      | 14/36 [00:03<00:07,  2.76it/s]\n",
      " 42%|████▏     | 15/36 [00:04<00:07,  2.70it/s]\n",
      " 44%|████▍     | 16/36 [00:04<00:07,  2.67it/s]\n",
      " 47%|████▋     | 17/36 [00:05<00:07,  2.64it/s]\n",
      " 50%|█████     | 18/36 [00:05<00:06,  2.61it/s]\n",
      " 53%|█████▎    | 19/36 [00:05<00:06,  2.59it/s]\n",
      " 56%|█████▌    | 20/36 [00:06<00:06,  2.59it/s]\n",
      " 58%|█████▊    | 21/36 [00:06<00:05,  2.59it/s]\n",
      " 61%|██████    | 22/36 [00:06<00:05,  2.58it/s]\n",
      " 64%|██████▍   | 23/36 [00:07<00:05,  2.57it/s]\n",
      " 67%|██████▋   | 24/36 [00:07<00:04,  2.57it/s]\n",
      " 69%|██████▉   | 25/36 [00:08<00:04,  2.57it/s]\n",
      " 72%|███████▏  | 26/36 [00:08<00:03,  2.57it/s]\n",
      " 75%|███████▌  | 27/36 [00:08<00:03,  2.57it/s]\n",
      " 78%|███████▊  | 28/36 [00:09<00:03,  2.59it/s]\n",
      " 81%|████████  | 29/36 [00:09<00:02,  2.59it/s]\n",
      " 83%|████████▎ | 30/36 [00:10<00:02,  2.58it/s]\n",
      " 86%|████████▌ | 31/36 [00:10<00:01,  2.57it/s]\n",
      " 89%|████████▉ | 32/36 [00:10<00:01,  2.57it/s]\n",
      " 92%|█████████▏| 33/36 [00:11<00:01,  2.57it/s]\n",
      " 94%|█████████▍| 34/36 [00:11<00:00,  2.57it/s]\n",
      " 97%|█████████▋| 35/36 [00:12<00:00,  2.60it/s]\n",
      "100%|██████████| 36/36 [00:12<00:00,  2.56it/s]\n",
      "100%|██████████| 36/36 [00:12<00:00,  2.90it/s]\n",
      "\n",
      "  0%|          | 0/36 [00:00<?, ?it/s]\n",
      " 14%|█▍        | 5/36 [00:00<00:02, 15.24it/s]\n",
      " 19%|█▉        | 7/36 [00:01<00:05,  5.47it/s]\n",
      " 22%|██▏       | 8/36 [00:01<00:06,  4.41it/s]\n",
      " 25%|██▌       | 9/36 [00:01<00:07,  3.77it/s]\n",
      " 28%|██▊       | 10/36 [00:02<00:07,  3.37it/s]\n",
      " 31%|███       | 11/36 [00:02<00:08,  3.09it/s]\n",
      " 33%|███▎      | 12/36 [00:03<00:08,  2.89it/s]\n",
      " 36%|███▌      | 13/36 [00:03<00:08,  2.75it/s]\n",
      " 39%|███▉      | 14/36 [00:03<00:08,  2.69it/s]\n",
      " 42%|████▏     | 15/36 [00:04<00:08,  2.61it/s]\n",
      " 44%|████▍     | 16/36 [00:04<00:07,  2.60it/s]\n",
      " 47%|████▋     | 17/36 [00:05<00:07,  2.55it/s]\n",
      " 50%|█████     | 18/36 [00:05<00:07,  2.55it/s]\n",
      " 53%|█████▎    | 19/36 [00:05<00:06,  2.54it/s]\n",
      " 56%|█████▌    | 20/36 [00:06<00:06,  2.51it/s]\n",
      " 58%|█████▊    | 21/36 [00:06<00:05,  2.53it/s]\n",
      " 61%|██████    | 22/36 [00:07<00:05,  2.50it/s]\n",
      " 64%|██████▍   | 23/36 [00:07<00:05,  2.51it/s]\n",
      " 67%|██████▋   | 24/36 [00:07<00:04,  2.49it/s]\n",
      " 69%|██████▉   | 25/36 [00:08<00:04,  2.51it/s]\n",
      " 72%|███████▏  | 26/36 [00:08<00:03,  2.52it/s]\n",
      " 75%|███████▌  | 27/36 [00:09<00:03,  2.52it/s]\n",
      " 78%|███████▊  | 28/36 [00:09<00:03,  2.50it/s]\n",
      " 81%|████████  | 29/36 [00:09<00:02,  2.48it/s]\n",
      " 83%|████████▎ | 30/36 [00:10<00:02,  2.51it/s]\n",
      " 86%|████████▌ | 31/36 [00:10<00:01,  2.52it/s]\n",
      " 89%|████████▉ | 32/36 [00:11<00:01,  2.53it/s]\n",
      " 92%|█████████▏| 33/36 [00:11<00:01,  2.53it/s]\n",
      " 94%|█████████▍| 34/36 [00:11<00:00,  2.53it/s]\n",
      " 97%|█████████▋| 35/36 [00:12<00:00,  2.57it/s]\n",
      "100%|██████████| 36/36 [00:12<00:00,  2.63it/s]\n",
      "100%|██████████| 36/36 [00:12<00:00,  2.86it/s]\n",
      "\n",
      "  0%|          | 0/36 [00:00<?, ?it/s]\n",
      " 14%|█▍        | 5/36 [00:00<00:02, 14.97it/s]\n",
      " 19%|█▉        | 7/36 [00:01<00:05,  5.52it/s]\n",
      " 22%|██▏       | 8/36 [00:01<00:06,  4.44it/s]\n",
      " 25%|██▌       | 9/36 [00:01<00:07,  3.85it/s]\n",
      " 28%|██▊       | 10/36 [00:02<00:07,  3.41it/s]\n",
      " 31%|███       | 11/36 [00:02<00:07,  3.14it/s]\n",
      " 33%|███▎      | 12/36 [00:03<00:08,  2.96it/s]\n",
      " 36%|███▌      | 13/36 [00:03<00:08,  2.86it/s]\n",
      " 39%|███▉      | 14/36 [00:03<00:07,  2.76it/s]\n",
      " 42%|████▏     | 15/36 [00:04<00:07,  2.72it/s]\n",
      " 44%|████▍     | 16/36 [00:04<00:07,  2.68it/s]\n",
      " 47%|████▋     | 17/36 [00:04<00:07,  2.68it/s]\n",
      " 50%|█████     | 18/36 [00:05<00:06,  2.61it/s]\n",
      " 53%|█████▎    | 19/36 [00:05<00:06,  2.63it/s]\n",
      " 56%|█████▌    | 20/36 [00:06<00:06,  2.61it/s]\n",
      " 58%|█████▊    | 21/36 [00:06<00:05,  2.63it/s]\n",
      " 61%|██████    | 22/36 [00:06<00:05,  2.61it/s]\n",
      " 64%|██████▍   | 23/36 [00:07<00:05,  2.59it/s]\n",
      " 67%|██████▋   | 24/36 [00:07<00:04,  2.62it/s]\n",
      " 69%|██████▉   | 25/36 [00:08<00:04,  2.60it/s]\n",
      " 72%|███████▏  | 26/36 [00:08<00:03,  2.62it/s]\n",
      " 75%|███████▌  | 27/36 [00:08<00:03,  2.60it/s]\n",
      " 78%|███████▊  | 28/36 [00:09<00:03,  2.62it/s]\n",
      " 81%|████████  | 29/36 [00:09<00:02,  2.60it/s]\n",
      " 83%|████████▎ | 30/36 [00:09<00:02,  2.60it/s]\n",
      " 86%|████████▌ | 31/36 [00:10<00:01,  2.61it/s]\n",
      " 89%|████████▉ | 32/36 [00:10<00:01,  2.58it/s]\n",
      " 92%|█████████▏| 33/36 [00:11<00:01,  2.57it/s]\n",
      " 94%|█████████▍| 34/36 [00:11<00:00,  2.54it/s]\n",
      " 97%|█████████▋| 35/36 [00:11<00:00,  2.55it/s]\n",
      "100%|██████████| 36/36 [00:12<00:00,  2.53it/s]\n",
      "100%|██████████| 36/36 [00:12<00:00,  2.92it/s]\n",
      "\n",
      "  0%|          | 0/27 [00:00<?, ?it/s]\n",
      " 19%|█▊        | 5/27 [00:00<00:01, 14.88it/s]\n",
      " 26%|██▌       | 7/27 [00:01<00:03,  5.53it/s]\n",
      " 30%|██▉       | 8/27 [00:01<00:04,  4.39it/s]\n",
      " 33%|███▎      | 9/27 [00:01<00:04,  3.81it/s]\n",
      " 37%|███▋      | 10/27 [00:02<00:05,  3.40it/s]\n",
      " 41%|████      | 11/27 [00:02<00:05,  3.17it/s]\n",
      " 44%|████▍     | 12/27 [00:03<00:04,  3.00it/s]\n",
      " 48%|████▊     | 13/27 [00:03<00:04,  2.85it/s]\n",
      " 52%|█████▏    | 14/27 [00:03<00:04,  2.74it/s]\n",
      " 56%|█████▌    | 15/27 [00:04<00:04,  2.68it/s]\n",
      " 59%|█████▉    | 16/27 [00:04<00:04,  2.65it/s]\n",
      " 63%|██████▎   | 17/27 [00:05<00:03,  2.58it/s]\n",
      " 67%|██████▋   | 18/27 [00:05<00:03,  2.57it/s]\n",
      " 70%|███████   | 19/27 [00:05<00:03,  2.56it/s]\n",
      " 74%|███████▍  | 20/27 [00:06<00:02,  2.56it/s]\n",
      " 78%|███████▊  | 21/27 [00:06<00:02,  2.56it/s]\n",
      " 81%|████████▏ | 22/27 [00:06<00:01,  2.63it/s]\n",
      " 85%|████████▌ | 23/27 [00:07<00:01,  2.57it/s]\n",
      " 89%|████████▉ | 24/27 [00:07<00:01,  2.57it/s]\n",
      " 93%|█████████▎| 25/27 [00:08<00:00,  2.57it/s]\n",
      " 96%|█████████▋| 26/27 [00:08<00:00,  2.59it/s]\n",
      "100%|██████████| 27/27 [00:08<00:00,  2.58it/s]\n",
      "100%|██████████| 27/27 [00:08<00:00,  3.03it/s]\n",
      "\n",
      "  0%|          | 0/27 [00:00<?, ?it/s]\n",
      " 19%|█▊        | 5/27 [00:00<00:01, 15.24it/s]\n",
      " 26%|██▌       | 7/27 [00:01<00:03,  5.52it/s]\n",
      " 30%|██▉       | 8/27 [00:01<00:04,  4.47it/s]\n",
      " 33%|███▎      | 9/27 [00:01<00:04,  3.81it/s]\n",
      " 37%|███▋      | 10/27 [00:02<00:04,  3.41it/s]\n",
      " 41%|████      | 11/27 [00:02<00:05,  3.17it/s]\n",
      " 44%|████▍     | 12/27 [00:03<00:05,  2.99it/s]\n",
      " 48%|████▊     | 13/27 [00:03<00:04,  2.87it/s]\n",
      " 52%|█████▏    | 14/27 [00:03<00:04,  2.77it/s]\n",
      " 56%|█████▌    | 15/27 [00:04<00:04,  2.74it/s]\n",
      " 59%|█████▉    | 16/27 [00:04<00:04,  2.69it/s]\n",
      " 63%|██████▎   | 17/27 [00:04<00:03,  2.63it/s]\n",
      " 67%|██████▋   | 18/27 [00:05<00:03,  2.60it/s]\n",
      " 70%|███████   | 19/27 [00:05<00:03,  2.59it/s]\n",
      " 74%|███████▍  | 20/27 [00:06<00:02,  2.59it/s]\n",
      " 78%|███████▊  | 21/27 [00:06<00:02,  2.59it/s]\n",
      " 81%|████████▏ | 22/27 [00:06<00:01,  2.58it/s]\n",
      " 85%|████████▌ | 23/27 [00:07<00:01,  2.60it/s]\n",
      " 89%|████████▉ | 24/27 [00:07<00:01,  2.60it/s]\n",
      " 93%|█████████▎| 25/27 [00:08<00:00,  2.59it/s]\n",
      " 96%|█████████▋| 26/27 [00:08<00:00,  2.58it/s]\n",
      "100%|██████████| 27/27 [00:08<00:00,  2.59it/s]\n",
      "100%|██████████| 27/27 [00:08<00:00,  3.05it/s]\n",
      "\n",
      "  0%|          | 0/27 [00:00<?, ?it/s]\n",
      " 19%|█▊        | 5/27 [00:00<00:01, 15.11it/s]\n",
      " 26%|██▌       | 7/27 [00:01<00:03,  5.52it/s]\n",
      " 30%|██▉       | 8/27 [00:01<00:04,  4.53it/s]\n",
      " 33%|███▎      | 9/27 [00:01<00:04,  3.86it/s]\n",
      " 37%|███▋      | 10/27 [00:02<00:04,  3.44it/s]\n",
      " 41%|████      | 11/27 [00:02<00:05,  3.15it/s]\n",
      " 44%|████▍     | 12/27 [00:03<00:05,  2.99it/s]\n",
      " 48%|████▊     | 13/27 [00:03<00:04,  2.84it/s]\n",
      " 52%|█████▏    | 14/27 [00:03<00:04,  2.71it/s]\n",
      " 56%|█████▌    | 15/27 [00:04<00:04,  2.66it/s]\n",
      " 59%|█████▉    | 16/27 [00:04<00:04,  2.61it/s]\n",
      " 63%|██████▎   | 17/27 [00:05<00:03,  2.57it/s]\n",
      " 67%|██████▋   | 18/27 [00:05<00:03,  2.56it/s]\n",
      " 70%|███████   | 19/27 [00:05<00:03,  2.57it/s]\n",
      " 74%|███████▍  | 20/27 [00:06<00:02,  2.55it/s]\n",
      " 78%|███████▊  | 21/27 [00:06<00:02,  2.54it/s]\n",
      " 81%|████████▏ | 22/27 [00:06<00:01,  2.54it/s]\n",
      " 85%|████████▌ | 23/27 [00:07<00:01,  2.54it/s]\n",
      " 89%|████████▉ | 24/27 [00:07<00:01,  2.54it/s]\n",
      " 93%|█████████▎| 25/27 [00:08<00:00,  2.50it/s]\n",
      " 96%|█████████▋| 26/27 [00:08<00:00,  2.49it/s]\n",
      "100%|██████████| 27/27 [00:09<00:00,  2.48it/s]\n",
      "100%|██████████| 27/27 [00:09<00:00,  3.00it/s]\n",
      "\n",
      "  0%|          | 0/36 [00:00<?, ?it/s]\n",
      " 14%|█▍        | 5/36 [00:00<00:02, 14.88it/s]\n",
      " 19%|█▉        | 7/36 [00:01<00:05,  5.26it/s]\n",
      " 22%|██▏       | 8/36 [00:01<00:06,  4.28it/s]\n",
      " 25%|██▌       | 9/36 [00:01<00:07,  3.65it/s]\n",
      " 28%|██▊       | 10/36 [00:02<00:07,  3.27it/s]\n",
      " 31%|███       | 11/36 [00:02<00:08,  3.03it/s]\n",
      " 33%|███▎      | 12/36 [00:03<00:08,  2.89it/s]\n",
      " 36%|███▌      | 13/36 [00:03<00:08,  2.76it/s]\n",
      " 39%|███▉      | 14/36 [00:03<00:08,  2.70it/s]\n",
      " 42%|████▏     | 15/36 [00:04<00:07,  2.63it/s]\n",
      " 44%|████▍     | 16/36 [00:04<00:07,  2.60it/s]\n",
      " 47%|████▋     | 17/36 [00:05<00:07,  2.55it/s]\n",
      " 50%|█████     | 18/36 [00:05<00:07,  2.55it/s]\n",
      " 53%|█████▎    | 19/36 [00:05<00:06,  2.52it/s]\n",
      " 56%|█████▌    | 20/36 [00:06<00:06,  2.53it/s]\n",
      " 58%|█████▊    | 21/36 [00:06<00:05,  2.53it/s]\n",
      " 61%|██████    | 22/36 [00:07<00:05,  2.51it/s]\n",
      " 64%|██████▍   | 23/36 [00:07<00:05,  2.52it/s]\n",
      " 67%|██████▋   | 24/36 [00:07<00:04,  2.50it/s]\n",
      " 69%|██████▉   | 25/36 [00:08<00:04,  2.49it/s]\n",
      " 72%|███████▏  | 26/36 [00:08<00:04,  2.48it/s]\n",
      " 75%|███████▌  | 27/36 [00:09<00:03,  2.48it/s]\n",
      " 78%|███████▊  | 28/36 [00:09<00:03,  2.47it/s]\n",
      " 81%|████████  | 29/36 [00:09<00:02,  2.46it/s]\n",
      " 83%|████████▎ | 30/36 [00:10<00:02,  2.46it/s]\n",
      " 86%|████████▌ | 31/36 [00:10<00:02,  2.46it/s]\n",
      " 89%|████████▉ | 32/36 [00:11<00:01,  2.46it/s]\n",
      " 92%|█████████▏| 33/36 [00:11<00:01,  2.46it/s]\n",
      " 94%|█████████▍| 34/36 [00:12<00:00,  2.48it/s]\n",
      " 97%|█████████▋| 35/36 [00:12<00:00,  2.47it/s]\n",
      "100%|██████████| 36/36 [00:12<00:00,  2.50it/s]\n",
      "100%|██████████| 36/36 [00:12<00:00,  2.81it/s]\n",
      "\n",
      "  0%|          | 0/36 [00:00<?, ?it/s]\n",
      " 14%|█▍        | 5/36 [00:00<00:02, 14.97it/s]\n",
      " 19%|█▉        | 7/36 [00:01<00:05,  5.26it/s]\n",
      " 22%|██▏       | 8/36 [00:01<00:06,  4.26it/s]\n",
      " 25%|██▌       | 9/36 [00:01<00:07,  3.64it/s]\n",
      " 28%|██▊       | 10/36 [00:02<00:07,  3.26it/s]\n",
      " 31%|███       | 11/36 [00:02<00:08,  2.99it/s]\n",
      " 33%|███▎      | 12/36 [00:03<00:08,  2.83it/s]\n",
      " 36%|███▌      | 13/36 [00:03<00:08,  2.72it/s]\n",
      " 39%|███▉      | 14/36 [00:03<00:08,  2.66it/s]\n",
      " 42%|████▏     | 15/36 [00:04<00:08,  2.62it/s]\n",
      " 44%|████▍     | 16/36 [00:04<00:07,  2.58it/s]\n",
      " 47%|████▋     | 17/36 [00:05<00:07,  2.54it/s]\n",
      " 50%|█████     | 18/36 [00:05<00:07,  2.50it/s]\n",
      " 53%|█████▎    | 19/36 [00:06<00:06,  2.50it/s]\n",
      " 56%|█████▌    | 20/36 [00:06<00:06,  2.50it/s]\n",
      " 58%|█████▊    | 21/36 [00:06<00:06,  2.49it/s]\n",
      " 61%|██████    | 22/36 [00:07<00:05,  2.51it/s]\n",
      " 64%|██████▍   | 23/36 [00:07<00:05,  2.47it/s]\n",
      " 67%|██████▋   | 24/36 [00:08<00:04,  2.46it/s]\n",
      " 69%|██████▉   | 25/36 [00:08<00:04,  2.47it/s]\n",
      " 72%|███████▏  | 26/36 [00:08<00:04,  2.47it/s]\n",
      " 75%|███████▌  | 27/36 [00:09<00:03,  2.49it/s]\n",
      " 78%|███████▊  | 28/36 [00:09<00:03,  2.46it/s]\n",
      " 81%|████████  | 29/36 [00:10<00:02,  2.46it/s]\n",
      " 83%|████████▎ | 30/36 [00:10<00:02,  2.48it/s]\n",
      " 86%|████████▌ | 31/36 [00:10<00:02,  2.48it/s]\n",
      " 89%|████████▉ | 32/36 [00:11<00:01,  2.48it/s]\n",
      " 92%|█████████▏| 33/36 [00:11<00:01,  2.50it/s]\n",
      " 94%|█████████▍| 34/36 [00:12<00:00,  2.48it/s]\n",
      " 97%|█████████▋| 35/36 [00:12<00:00,  2.50it/s]\n",
      "100%|██████████| 36/36 [00:12<00:00,  2.49it/s]\n",
      "100%|██████████| 36/36 [00:12<00:00,  2.80it/s]\n",
      "\n",
      "  0%|          | 0/27 [00:00<?, ?it/s]\n",
      " 19%|█▊        | 5/27 [00:00<00:01, 14.75it/s]\n",
      " 26%|██▌       | 7/27 [00:01<00:03,  5.22it/s]\n",
      " 30%|██▉       | 8/27 [00:01<00:04,  4.29it/s]\n",
      " 33%|███▎      | 9/27 [00:01<00:04,  3.68it/s]\n",
      " 37%|███▋      | 10/27 [00:02<00:05,  3.33it/s]\n",
      " 41%|████      | 11/27 [00:02<00:05,  3.04it/s]\n",
      " 44%|████▍     | 12/27 [00:03<00:05,  2.88it/s]\n",
      " 48%|████▊     | 13/27 [00:03<00:05,  2.76it/s]\n",
      " 52%|█████▏    | 14/27 [00:03<00:04,  2.70it/s]\n",
      " 56%|█████▌    | 15/27 [00:04<00:04,  2.63it/s]\n",
      " 59%|█████▉    | 16/27 [00:04<00:04,  2.61it/s]\n",
      " 63%|██████▎   | 17/27 [00:05<00:03,  2.57it/s]\n",
      " 67%|██████▋   | 18/27 [00:05<00:03,  2.57it/s]\n",
      " 70%|███████   | 19/27 [00:05<00:03,  2.54it/s]\n",
      " 74%|███████▍  | 20/27 [00:06<00:02,  2.55it/s]\n",
      " 78%|███████▊  | 21/27 [00:06<00:02,  2.52it/s]\n",
      " 81%|████████▏ | 22/27 [00:07<00:01,  2.52it/s]\n",
      " 85%|████████▌ | 23/27 [00:07<00:01,  2.51it/s]\n",
      " 89%|████████▉ | 24/27 [00:07<00:01,  2.53it/s]\n",
      " 93%|█████████▎| 25/27 [00:08<00:00,  2.51it/s]\n",
      " 96%|█████████▋| 26/27 [00:08<00:00,  2.52it/s]\n",
      "100%|██████████| 27/27 [00:09<00:00,  2.51it/s]\n",
      "100%|██████████| 27/27 [00:09<00:00,  2.96it/s]\n",
      "\n",
      "  0%|          | 0/27 [00:00<?, ?it/s]\n",
      " 19%|█▊        | 5/27 [00:00<00:01, 15.06it/s]\n",
      " 26%|██▌       | 7/27 [00:01<00:03,  5.28it/s]\n",
      " 30%|██▉       | 8/27 [00:01<00:04,  4.32it/s]\n",
      " 33%|███▎      | 9/27 [00:01<00:04,  3.69it/s]\n",
      " 37%|███▋      | 10/27 [00:02<00:05,  3.33it/s]\n",
      " 41%|████      | 11/27 [00:02<00:05,  3.05it/s]\n",
      " 44%|████▍     | 12/27 [00:03<00:05,  2.90it/s]\n",
      " 48%|████▊     | 13/27 [00:03<00:05,  2.77it/s]\n",
      " 52%|█████▏    | 14/27 [00:03<00:04,  2.68it/s]\n",
      " 56%|█████▌    | 15/27 [00:04<00:04,  2.65it/s]\n",
      " 59%|█████▉    | 16/27 [00:04<00:04,  2.59it/s]\n",
      " 63%|██████▎   | 17/27 [00:05<00:03,  2.57it/s]\n",
      " 67%|██████▋   | 18/27 [00:05<00:03,  2.57it/s]\n",
      " 70%|███████   | 19/27 [00:05<00:03,  2.53it/s]\n",
      " 74%|███████▍  | 20/27 [00:06<00:02,  2.54it/s]\n",
      " 78%|███████▊  | 21/27 [00:06<00:02,  2.51it/s]\n",
      " 81%|████████▏ | 22/27 [00:07<00:01,  2.53it/s]\n",
      " 85%|████████▌ | 23/27 [00:07<00:01,  2.51it/s]\n",
      " 89%|████████▉ | 24/27 [00:07<00:01,  2.54it/s]\n",
      " 93%|█████████▎| 25/27 [00:08<00:00,  2.52it/s]\n",
      " 96%|█████████▋| 26/27 [00:08<00:00,  2.51it/s]\n",
      "100%|██████████| 27/27 [00:09<00:00,  2.52it/s]\n",
      "100%|██████████| 27/27 [00:09<00:00,  2.97it/s]\n",
      "\n",
      "  0%|          | 0/27 [00:00<?, ?it/s]\n",
      " 19%|█▊        | 5/27 [00:00<00:01, 14.29it/s]\n",
      " 26%|██▌       | 7/27 [00:01<00:03,  5.28it/s]\n",
      " 30%|██▉       | 8/27 [00:01<00:04,  4.27it/s]\n",
      " 33%|███▎      | 9/27 [00:01<00:04,  3.67it/s]\n",
      " 37%|███▋      | 10/27 [00:02<00:05,  3.28it/s]\n",
      " 41%|████      | 11/27 [00:02<00:05,  3.06it/s]\n",
      " 44%|████▍     | 12/27 [00:03<00:05,  2.88it/s]\n",
      " 48%|████▊     | 13/27 [00:03<00:05,  2.78it/s]\n",
      " 52%|█████▏    | 14/27 [00:03<00:04,  2.68it/s]\n",
      " 56%|█████▌    | 15/27 [00:04<00:04,  2.64it/s]\n",
      " 59%|█████▉    | 16/27 [00:04<00:04,  2.58it/s]\n",
      " 63%|██████▎   | 17/27 [00:05<00:03,  2.58it/s]\n",
      " 67%|██████▋   | 18/27 [00:05<00:03,  2.54it/s]\n",
      " 70%|███████   | 19/27 [00:05<00:03,  2.53it/s]\n",
      " 74%|███████▍  | 20/27 [00:06<00:02,  2.54it/s]\n",
      " 78%|███████▊  | 21/27 [00:06<00:02,  2.53it/s]\n",
      " 81%|████████▏ | 22/27 [00:07<00:01,  2.51it/s]\n",
      " 85%|████████▌ | 23/27 [00:07<00:01,  2.50it/s]\n",
      " 89%|████████▉ | 24/27 [00:07<00:01,  2.51it/s]\n",
      " 93%|█████████▎| 25/27 [00:08<00:00,  2.50it/s]\n",
      " 96%|█████████▋| 26/27 [00:08<00:00,  2.52it/s]\n",
      "100%|██████████| 27/27 [00:09<00:00,  2.50it/s]\n",
      "100%|██████████| 27/27 [00:09<00:00,  2.96it/s]\n"
     ]
    }
   ],
   "source": [
    "!nnUNetv2_predict -i \"C:\\\\Users\\\\CUTY\\\\Desktop\\\\AOR\\\\nnU_Base\\\\nnUNet_raw_data\\\\Dataset001_MYTASK\\\\imagesTs\" \\\n",
    "                  -o \"C:\\\\Users\\\\CUTY\\\\Desktop\\\\AOR\\\\nnU_Base\\\\nnUnet_predictions\" \\\n",
    "                  -d 1 -c 3d_fullres -f 1 -p nnUNetResEncUNetLPlans --disable_tta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 6554989,
     "status": "ok",
     "timestamp": 1742294377389,
     "user": {
      "displayName": "LAB AI",
      "userId": "05090763676444143877"
     },
     "user_tz": -480
    },
    "id": "z06-kAkXaytR",
    "outputId": "8ee28372-c093-43a5-b74f-9ce0ec28ee28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#######################################################################\n",
      "Please cite the following paper when using nnU-Net:\n",
      "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
      "#######################################################################\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Scripts\\nnUNetv2_predict.exe\\__main__.py\", line 7, in <module>\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\nnunetv2\\inference\\predict_from_raw_data.py\", line 979, in predict_entry_point\n",
      "    predictor.initialize_from_trained_model_folder(\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\nnunetv2\\inference\\predict_from_raw_data.py\", line 76, in initialize_from_trained_model_folder\n",
      "    dataset_json = load_json(join(model_training_output_dir, 'dataset.json'))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\batchgenerators\\utilities\\file_and_folder_operations.py\", line 103, in load_json\n",
      "    with open(file, 'r') as f:\n",
      "         ^^^^^^^^^^^^^^^\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'C:\\\\Users\\\\CUTY\\\\Desktop\\\\AOR\\\\nnU_Base\\\\nnUNet_trained_models\\\\Dataset003_aocr2024_partial\\\\nnUNetTrainer__nnUNetResEncUNetLPlans__3d_fullres\\\\dataset.json'\n"
     ]
    }
   ],
   "source": [
    "# !nnUNetv2_predict -d Dataset003_aocr2024_partial \\\n",
    "#     -i \"/content/input_partial\" \\\n",
    "#     -o \"/content/drive/MyDrive/poster/NNUNET/predict/Dataset003_aocr2024_partial/nnUNetTrainer__nnUNetResEncUNetLPlans__3d_fullres/fold_0_1_3/output\" \\\n",
    "#     -f  0 1 3 \\\n",
    "#     -tr nnUNetTrainer \\\n",
    "#     -c 3d_fullres \\\n",
    "#     -p nnUNetResEncUNetLPlans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bz7MLtOtt_IK"
   },
   "source": [
    "## postprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功將預測結果儲存為 scan-slice-level labels CSV：C:\\Users\\CUTY\\Desktop\\AOR\\scan_slice_level_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 設定測試集預測結果資料夾\n",
    "pred_dir = r\"C:\\Users\\CUTY\\Desktop\\AOR\\nnU_Base\\nnUnet_predictions\"\n",
    "\n",
    "# 儲存 slice-level labels 的 CSV 路徑\n",
    "output_csv_path = r\"C:\\Users\\CUTY\\Desktop\\AOR\\scan_slice_level_predictions.csv\"\n",
    "\n",
    "# 建立用來儲存 CSV 資料的列表\n",
    "records = []\n",
    "\n",
    "# 遍歷預測資料夾，處理每個 .nii.gz 檔案\n",
    "for filename in os.listdir(pred_dir):\n",
    "    if filename.endswith('.nii.gz'):\n",
    "        pred_filepath = os.path.join(pred_dir, filename)\n",
    "        pred_img = nib.load(pred_filepath)\n",
    "        pred_data = pred_img.get_fdata()\n",
    "\n",
    "        # 提取 Scan name (假設檔案命名如 Sample_0, Sample_1, 等等)\n",
    "        scan_name = filename.split('_')[0]\n",
    "\n",
    "        # 根據 slice-level 預測推算 scan-level 標籤\n",
    "        # 只要任一 slice 預測為發炎（label=1），就視為整個 scan 為發炎\n",
    "        slices_with_inflammation = (pred_data == 1).sum(axis=(0, 1)) > 0\n",
    "        scan_pred = 1 if np.any(slices_with_inflammation) else 0\n",
    "\n",
    "        # 記錄 scan-level 的資料\n",
    "        records.append({\n",
    "            \"id\": scan_name,  # scan-level id（例如 Sample）\n",
    "            \"label\": scan_pred  # scan-level 預測結果\n",
    "        })\n",
    "\n",
    "        # 逐切片處理，檢查每個 slice 是否預測為發炎區\n",
    "        for slice_idx in range(pred_data.shape[2]):\n",
    "            # 檢查這個 slice 是否有發炎（即 label=1）\n",
    "            slice_data = pred_data[:, :, slice_idx]\n",
    "            slice_label = 1 if np.any(slice_data == 1) else 0  # 只要有任何像素為 1，就判定為發炎區\n",
    "\n",
    "            # 記錄 slice-level 資料\n",
    "            records.append({\n",
    "                \"id\": f\"{scan_name}_{slice_idx}\",  # 生成 slice 的 id（例如 Sample_0）\n",
    "                \"label\": slice_label  # 這個 slice 的標籤\n",
    "            })\n",
    "\n",
    "# 儲存為 CSV\n",
    "df = pd.DataFrame(records)\n",
    "df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"成功將預測結果儲存為 scan-slice-level labels CSV：{output_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth Data:\n",
      "     id  label\n",
      "0    AA      1\n",
      "1  AA_0      0\n",
      "2  AA_1      0\n",
      "3  AA_2      0\n",
      "4  AA_3      0\n",
      "Prediction Data:\n",
      "     id  label\n",
      "0    AA      1\n",
      "1  AA_0      0\n",
      "2  AA_1      0\n",
      "3  AA_2      1\n",
      "4  AA_3      1\n",
      "Slice-level Precision: 0.0682\n",
      "Slice-level Recall: 0.7255\n",
      "Slice-level F1 Score: 0.1247\n",
      "\n",
      "Scan-level Precision: 0.5000\n",
      "Scan-level Recall: 1.0000\n",
      "Scan-level F1 Score: 0.6667\n",
      "Merged DataFrame:\n",
      "     id  label_gt  label_pred\n",
      "0    AA         1           1\n",
      "1  AA_0         0           0\n",
      "2  AA_1         0           0\n",
      "3  AA_2         0           1\n",
      "4  AA_3         0           1\n",
      "\n",
      "Merged and saved results to: C:\\Users\\CUTY\\Desktop\\AOR\\final_results_with_f1.csv\n",
      "\n",
      "Average F1 Score for Slice-level: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# # 讀取 ground truth 的 slice-level labels\n",
    "# gt_path = r\"C:\\Users\\CUTY\\Desktop\\AOR\\test_team1_ground_truth.csv\"\n",
    "# gt_df = pd.read_csv(gt_path)\n",
    "\n",
    "# # 讀取預測的 slice-level labels\n",
    "# pred_path = r\"C:\\Users\\CUTY\\Desktop\\AOR\\scan_slice_level_predictions.csv\"\n",
    "# pred_df = pd.read_csv(pred_path)\n",
    "\n",
    "# # 處理預測資料的 id 格式，將 \".nii.gz\" 去掉以便與 ground truth 的 id 格式一致\n",
    "# # 但保留 slice 索引（例如 AA_0, AA_1）\n",
    "# pred_df['id'] = pred_df['id'].apply(lambda x: x.replace('.nii.gz', ''))  # 保留主檔名，不去掉 slice 索引\n",
    "\n",
    "# # 確保預測和 ground truth 的 id 在合併時匹配\n",
    "# # Ground truth 的 id 會有 AA, AA_0, AA_1, AA_2, ... 所以需要處理這個\n",
    "# # 根據相同的主檔名來將預測結果對應到每個 slice\n",
    "# gt_df['id'] = gt_df['id'].apply(lambda x: x.split('.')[0])  # 同樣處理 ground truth，去掉 .nii.gz\n",
    "\n",
    "# # 檢查資料是否正確載入\n",
    "# print(\"Ground Truth Data:\")\n",
    "# print(gt_df.head())  # 顯示 ground truth 的前幾行\n",
    "# print(\"Prediction Data:\")\n",
    "# print(pred_df.head())  # 顯示預測結果的前幾行\n",
    "\n",
    "# # 1. 計算 slice-level F1\n",
    "# # 比較預測結果與 ground truth\n",
    "# y_true = gt_df['label'].values\n",
    "# y_pred = pred_df['label'].values\n",
    "\n",
    "# # 計算 F1 分數\n",
    "# precision_s, recall_s, f1_s, _ = precision_recall_fscore_support(y_true, y_pred, average='binary')\n",
    "\n",
    "# print(f\"Slice-level Precision: {precision_s:.4f}\")\n",
    "# print(f\"Slice-level Recall: {recall_s:.4f}\")\n",
    "# print(f\"Slice-level F1 Score: {f1_s:.4f}\")\n",
    "\n",
    "# # 2. 計算 scan-level F1\n",
    "# # 根據 slice-level 預測來推算 scan-level 預測\n",
    "# # 如果該 scan 中任一 slice 預測為發炎，則整個 scan 視為發炎\n",
    "# scan_gt = {}\n",
    "# scan_pred = {}\n",
    "\n",
    "# # 取得 scan-level ground truth\n",
    "# current_scan = None\n",
    "# for idx, row in gt_df.iterrows():\n",
    "#     if '_' not in row['id']:  # scan-level行\n",
    "#         current_scan = row['id']\n",
    "#         scan_gt[current_scan] = row['label']\n",
    "\n",
    "# # 取得 slice-level 預測\n",
    "# for idx, row in pred_df.iterrows():\n",
    "#     scan_name = row['id'].split('_')[0]  # Scan 名稱是 slice 名稱的前綴（例如 Sample_0 -> Sample）\n",
    "#     slice_label = row['label']\n",
    "\n",
    "#     # 根據所有 slice 預測來決定 scan-level 預測\n",
    "#     if scan_name not in scan_pred:\n",
    "#         scan_pred[scan_name] = 0  # 初始化為正常（0）\n",
    "\n",
    "#     if slice_label == 1:\n",
    "#         scan_pred[scan_name] = 1  # 只要一個 slice 被預測為發炎，scan 就是發炎\n",
    "\n",
    "# # 3. 計算 scan-level F1\n",
    "# scan_gt_labels = list(scan_gt.values())\n",
    "# scan_pred_labels = [scan_pred.get(scan, 0) for scan in scan_gt.keys()]\n",
    "\n",
    "# # 如果 scan_pred_labels 和 scan_gt_labels 都有有效的預測，計算 F1\n",
    "# if len(scan_pred_labels) > 0 and len(scan_gt_labels) > 0:\n",
    "#     precision_sc, recall_sc, f1_sc, _ = precision_recall_fscore_support(scan_gt_labels, scan_pred_labels, average='binary')\n",
    "# else:\n",
    "#     precision_sc, recall_sc, f1_sc = 0, 0, 0\n",
    "\n",
    "# print(f\"\\nScan-level Precision: {precision_sc:.4f}\")\n",
    "# print(f\"Scan-level Recall: {recall_sc:.4f}\")\n",
    "# print(f\"Scan-level F1 Score: {f1_sc:.4f}\")\n",
    "\n",
    "# # 4. 合併 ground truth 和預測結果\n",
    "# # 合併兩個資料框\n",
    "# merged_df = pd.merge(gt_df, pred_df, on='id', suffixes=('_gt', '_pred'))\n",
    "\n",
    "# # 檢查合併後的結果\n",
    "# print(\"Merged DataFrame:\")\n",
    "# print(merged_df.head())  # 顯示合併後的前幾行\n",
    "\n",
    "# # 計算每個 slice 的 TP, FP, FN 和 F1\n",
    "# merged_df['TP'] = ((merged_df['label_gt'] == 1) & (merged_df['label_pred'] == 1)).astype(int)\n",
    "# merged_df['FP'] = ((merged_df['label_gt'] == 0) & (merged_df['label_pred'] == 1)).astype(int)\n",
    "# merged_df['FN'] = ((merged_df['label_gt'] == 1) & (merged_df['label_pred'] == 0)).astype(int)\n",
    "\n",
    "# # 計算每個 slice 的 precision, recall, f1\n",
    "# merged_df['Precision'] = merged_df['TP'] / (merged_df['TP'] + merged_df['FP']) if (merged_df['TP'] + merged_df['FP']).sum() > 0 else 0\n",
    "# merged_df['Recall'] = merged_df['TP'] / (merged_df['TP'] + merged_df['FN']) if (merged_df['TP'] + merged_df['FN']).sum() > 0 else 0\n",
    "# merged_df['F1'] = 2 * (merged_df['Precision'] * merged_df['Recall']) / (merged_df['Precision'] + merged_df['Recall']) if (merged_df['Precision'] + merged_df['Recall']).sum() > 0 else 0\n",
    "\n",
    "# # 保存合併結果到 CSV\n",
    "# output_csv_path = r\"C:\\Users\\CUTY\\Desktop\\AOR\\final_results_with_f1.csv\"\n",
    "# merged_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "# print(f\"\\nMerged and saved results to: {output_csv_path}\")\n",
    "\n",
    "# # 平均 F1 分數\n",
    "# avg_f1_slice = merged_df['F1'].mean()\n",
    "# print(f\"\\nAverage F1 Score for Slice-level: {avg_f1_slice:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slice-level F1 Score: 0.1247\n",
      "Scan-level F1 Score: 0.6667\n",
      "Finished saving F1 Score to: C:\\Users\\CUTY\\Desktop\\AOR\\final_results_with_f1.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# 讀取 ground truth 的 slice-level labels\n",
    "gt_path = r\"C:\\Users\\CUTY\\Desktop\\AOR\\test_team1_ground_truth.csv\"\n",
    "gt_df = pd.read_csv(gt_path)\n",
    "\n",
    "# 讀取預測的 slice-level labels\n",
    "pred_path = r\"C:\\Users\\CUTY\\Desktop\\AOR\\scan_slice_level_predictions.csv\"\n",
    "pred_df = pd.read_csv(pred_path)\n",
    "\n",
    "# 處理預測資料的 id 格式，將 \".nii.gz\" 去掉以便與 ground truth 的 id 格式一致\n",
    "# 但保留 slice 索引（例如 AA_0, AA_1）\n",
    "pred_df['id'] = pred_df['id'].apply(lambda x: x.replace('.nii.gz', ''))  # 保留主檔名，不去掉 slice 索引\n",
    "\n",
    "# 確保預測和 ground truth 的 id 在合併時匹配\n",
    "# Ground truth 的 id 會有 AA, AA_0, AA_1, AA_2, ... 所以需要處理這個\n",
    "# 根據相同的主檔名來將預測結果對應到每個 slice\n",
    "gt_df['id'] = gt_df['id'].apply(lambda x: x.split('.')[0])  # 同樣處理 ground truth，去掉 .nii.gz\n",
    "\n",
    "# 1. 計算 slice-level F1\n",
    "# 比較預測結果與 ground truth\n",
    "y_true = gt_df['label'].values\n",
    "y_pred = pred_df['label'].values\n",
    "\n",
    "# 計算 F1 分數\n",
    "precision_s, recall_s, f1_s, _ = precision_recall_fscore_support(y_true, y_pred, average='binary')\n",
    "\n",
    "print(f\"Slice-level F1 Score: {f1_s:.4f}\")\n",
    "\n",
    "# 2. 計算 scan-level F1\n",
    "# 根據 slice-level 預測來推算 scan-level 預測\n",
    "# 如果該 scan 中任一 slice 預測為發炎，則整個 scan 視為發炎\n",
    "scan_gt = {}\n",
    "scan_pred = {}\n",
    "\n",
    "# 取得 scan-level ground truth\n",
    "current_scan = None\n",
    "for idx, row in gt_df.iterrows():\n",
    "    if '_' not in row['id']:  # scan-level行\n",
    "        current_scan = row['id']\n",
    "        scan_gt[current_scan] = row['label']\n",
    "\n",
    "# 取得 slice-level 預測\n",
    "for idx, row in pred_df.iterrows():\n",
    "    scan_name = row['id'].split('_')[0]  # Scan 名稱是 slice 名稱的前綴（例如 Sample_0 -> Sample）\n",
    "    slice_label = row['label']\n",
    "\n",
    "    # 根據所有 slice 預測來決定 scan-level 預測\n",
    "    if scan_name not in scan_pred:\n",
    "        scan_pred[scan_name] = 0  # 初始化為正常（0）\n",
    "\n",
    "    if slice_label == 1:\n",
    "        scan_pred[scan_name] = 1  # 只要一個 slice 被預測為發炎，scan 就是發炎\n",
    "\n",
    "# 3. 計算 scan-level F1\n",
    "scan_gt_labels = list(scan_gt.values())\n",
    "scan_pred_labels = [scan_pred.get(scan, 0) for scan in scan_gt.keys()]\n",
    "\n",
    "# 計算 Scan-level F1\n",
    "precision_sc, recall_sc, f1_sc, _ = precision_recall_fscore_support(scan_gt_labels, scan_pred_labels, average='binary')\n",
    "\n",
    "print(f\"Scan-level F1 Score: {f1_sc:.4f}\")\n",
    "\n",
    "# 4. 合併 ground truth 和預測結果\n",
    "# 合併兩個資料框\n",
    "merged_df = pd.merge(gt_df, pred_df, on='id', suffixes=('_gt', '_pred'))\n",
    "\n",
    "# 計算每個 slice 的 F1\n",
    "merged_df['TP'] = ((merged_df['label_gt'] == 1) & (merged_df['label_pred'] == 1)).astype(int)\n",
    "merged_df['FP'] = ((merged_df['label_gt'] == 0) & (merged_df['label_pred'] == 1)).astype(int)\n",
    "merged_df['FN'] = ((merged_df['label_gt'] == 1) & (merged_df['label_pred'] == 0)).astype(int)\n",
    "\n",
    "# 計算每個 slice 的 f1\n",
    "merged_df['F1'] = 2 * (merged_df['TP'] * merged_df['TP']) / (merged_df['TP'] + merged_df['TP'])\n",
    "\n",
    "# 保存合併結果到 CSV\n",
    "output_csv_path = r\"C:\\Users\\CUTY\\Desktop\\AOR\\final_results_with_f1.csv\"\n",
    "merged_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"Finished saving F1 Score to: {output_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UMDC8n76lMje"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Scripts\\nnUNetv2_apply_postprocessing.exe\\__main__.py\", line 7, in <module>\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\nnunetv2\\postprocessing\\remove_connected_components.py\", line 332, in entry_point_apply_postprocessing\n",
      "    pp_fns, pp_fn_kwargs = load_pickle(args.pp_pkl_file)\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\CUTY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\batchgenerators\\utilities\\file_and_folder_operations.py\", line 92, in load_pickle\n",
      "    with open(file, mode) as f:\n",
      "         ^^^^^^^^^^^^^^^^\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/poster/NNUNET/nnUNet_results/Dataset003_aocr2024_partial/nnUNetTrainer__nnUNetResEncUNetLPlans__3d_fullres/crossval_results_folds_0_1_3/postprocessing.pkl'\n"
     ]
    }
   ],
   "source": [
    "# !nnUNetv2_apply_postprocessing \\\n",
    "#     -i '/content/drive/MyDrive/poster/NNUNET/predict/Dataset003_aocr2024_partial/nnUNetTrainer__nnUNetResEncUNetLPlans__3d_fullres/fold_0_1_3/output' \\\n",
    "#     -o '/content/drive/MyDrive/poster/NNUNET/predict/Dataset003_aocr2024_partial/nnUNetTrainer__nnUNetResEncUNetLPlans__3d_fullres/fold_0_1_3/output_pp' \\\n",
    "#     -pp_pkl_file /content/drive/MyDrive/poster/NNUNET/nnUNet_results/Dataset003_aocr2024_partial/nnUNetTrainer__nnUNetResEncUNetLPlans__3d_fullres/crossval_results_folds_0_1_3/postprocessing.pkl \\\n",
    "#     -np 8 \\\n",
    "#     -plans_json /content/drive/MyDrive/poster/NNUNET/nnUNet_results/Dataset003_aocr2024_partial/nnUNetTrainer__nnUNetResEncUNetLPlans__3d_fullres/crossval_results_folds_0_1_3/plans.json"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": [
    {
     "file_id": "1idCQZ7WhsgNGF5N2Yxc7Zlnic3-3PfSe",
     "timestamp": 1742895915455
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
